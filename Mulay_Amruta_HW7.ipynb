{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4711642f",
   "metadata": {},
   "source": [
    "## Name : Amruta Mulay , Github Username : Amruta131198 , USC ID : 6897885438"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "253217ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all necessary libraries required for HW-6\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.metrics import hamming_loss\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65ef098",
   "metadata": {},
   "source": [
    "## 1. Multi-class and Multi-Label Classification Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8d0e2b",
   "metadata": {},
   "source": [
    "**1(a). Download the Anuran Calls (MFCCs) Data Set from: https://archive.ics.uci.edu/ml/datasets/Anuran+Calls+%28MFCCs%29. Choose 70% of the data randomly as the training set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cc344dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "      <th>RecordID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152936</td>\n",
       "      <td>-0.105586</td>\n",
       "      <td>0.200722</td>\n",
       "      <td>0.317201</td>\n",
       "      <td>0.260764</td>\n",
       "      <td>0.100945</td>\n",
       "      <td>-0.150063</td>\n",
       "      <td>-0.171128</td>\n",
       "      <td>0.124676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108351</td>\n",
       "      <td>-0.077623</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.057684</td>\n",
       "      <td>0.118680</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171534</td>\n",
       "      <td>-0.098975</td>\n",
       "      <td>0.268425</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.268353</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>-0.222475</td>\n",
       "      <td>-0.207693</td>\n",
       "      <td>0.170883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090974</td>\n",
       "      <td>-0.056510</td>\n",
       "      <td>-0.035303</td>\n",
       "      <td>0.020140</td>\n",
       "      <td>0.082263</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152317</td>\n",
       "      <td>-0.082973</td>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.276014</td>\n",
       "      <td>0.189867</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.242234</td>\n",
       "      <td>-0.219153</td>\n",
       "      <td>0.232538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050691</td>\n",
       "      <td>-0.023590</td>\n",
       "      <td>-0.066722</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.077162</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.224392</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.329432</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>-0.194347</td>\n",
       "      <td>-0.098181</td>\n",
       "      <td>0.270375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136009</td>\n",
       "      <td>-0.177037</td>\n",
       "      <td>-0.130498</td>\n",
       "      <td>-0.054766</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>-0.068345</td>\n",
       "      <td>0.306967</td>\n",
       "      <td>0.330923</td>\n",
       "      <td>0.249144</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>-0.265423</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048885</td>\n",
       "      <td>-0.053074</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>0.108610</td>\n",
       "      <td>0.079244</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7190</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.554504</td>\n",
       "      <td>-0.337717</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.034511</td>\n",
       "      <td>0.443451</td>\n",
       "      <td>0.093889</td>\n",
       "      <td>-0.100753</td>\n",
       "      <td>0.037087</td>\n",
       "      <td>0.081075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069430</td>\n",
       "      <td>0.071001</td>\n",
       "      <td>0.021591</td>\n",
       "      <td>0.052449</td>\n",
       "      <td>-0.021860</td>\n",
       "      <td>-0.079860</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7191</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.517273</td>\n",
       "      <td>-0.370574</td>\n",
       "      <td>0.030673</td>\n",
       "      <td>0.068097</td>\n",
       "      <td>0.402890</td>\n",
       "      <td>0.096628</td>\n",
       "      <td>-0.116460</td>\n",
       "      <td>0.063727</td>\n",
       "      <td>0.089034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061127</td>\n",
       "      <td>0.068978</td>\n",
       "      <td>0.017745</td>\n",
       "      <td>0.046461</td>\n",
       "      <td>-0.015418</td>\n",
       "      <td>-0.101892</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7192</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.582557</td>\n",
       "      <td>-0.343237</td>\n",
       "      <td>0.029468</td>\n",
       "      <td>0.064179</td>\n",
       "      <td>0.385596</td>\n",
       "      <td>0.114905</td>\n",
       "      <td>-0.103317</td>\n",
       "      <td>0.070370</td>\n",
       "      <td>0.081317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.077771</td>\n",
       "      <td>-0.009688</td>\n",
       "      <td>0.027834</td>\n",
       "      <td>-0.000531</td>\n",
       "      <td>-0.080425</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7193</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.519497</td>\n",
       "      <td>-0.307553</td>\n",
       "      <td>-0.004922</td>\n",
       "      <td>0.072865</td>\n",
       "      <td>0.377131</td>\n",
       "      <td>0.086866</td>\n",
       "      <td>-0.115799</td>\n",
       "      <td>0.056979</td>\n",
       "      <td>0.089316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051796</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>0.017963</td>\n",
       "      <td>0.041803</td>\n",
       "      <td>-0.027911</td>\n",
       "      <td>-0.096895</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7194</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.508833</td>\n",
       "      <td>-0.324106</td>\n",
       "      <td>0.062068</td>\n",
       "      <td>0.078211</td>\n",
       "      <td>0.397188</td>\n",
       "      <td>0.094596</td>\n",
       "      <td>-0.117672</td>\n",
       "      <td>0.058874</td>\n",
       "      <td>0.076180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061455</td>\n",
       "      <td>0.072983</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>0.031560</td>\n",
       "      <td>-0.029355</td>\n",
       "      <td>-0.087910</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7195 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "0          1.0  0.152936 -0.105586  0.200722  0.317201  0.260764  0.100945   \n",
       "1          1.0  0.171534 -0.098975  0.268425  0.338672  0.268353  0.060835   \n",
       "2          1.0  0.152317 -0.082973  0.287128  0.276014  0.189867  0.008714   \n",
       "3          1.0  0.224392  0.118985  0.329432  0.372088  0.361005  0.015501   \n",
       "4          1.0  0.087817 -0.068345  0.306967  0.330923  0.249144  0.006884   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7190       1.0 -0.554504 -0.337717  0.035533  0.034511  0.443451  0.093889   \n",
       "7191       1.0 -0.517273 -0.370574  0.030673  0.068097  0.402890  0.096628   \n",
       "7192       1.0 -0.582557 -0.343237  0.029468  0.064179  0.385596  0.114905   \n",
       "7193       1.0 -0.519497 -0.307553 -0.004922  0.072865  0.377131  0.086866   \n",
       "7194       1.0 -0.508833 -0.324106  0.062068  0.078211  0.397188  0.094596   \n",
       "\n",
       "      MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_17  MFCCs_18  MFCCs_19  \\\n",
       "0    -0.150063 -0.171128  0.124676  ... -0.108351 -0.077623 -0.009568   \n",
       "1    -0.222475 -0.207693  0.170883  ... -0.090974 -0.056510 -0.035303   \n",
       "2    -0.242234 -0.219153  0.232538  ... -0.050691 -0.023590 -0.066722   \n",
       "3    -0.194347 -0.098181  0.270375  ... -0.136009 -0.177037 -0.130498   \n",
       "4    -0.265423 -0.172700  0.266434  ... -0.048885 -0.053074 -0.088550   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7190 -0.100753  0.037087  0.081075  ...  0.069430  0.071001  0.021591   \n",
       "7191 -0.116460  0.063727  0.089034  ...  0.061127  0.068978  0.017745   \n",
       "7192 -0.103317  0.070370  0.081317  ...  0.082474  0.077771 -0.009688   \n",
       "7193 -0.115799  0.056979  0.089316  ...  0.051796  0.069073  0.017963   \n",
       "7194 -0.117672  0.058874  0.076180  ...  0.061455  0.072983 -0.003980   \n",
       "\n",
       "      MFCCs_20  MFCCs_21  MFCCs_22           Family      Genus  \\\n",
       "0     0.057684  0.118680  0.014038  Leptodactylidae  Adenomera   \n",
       "1     0.020140  0.082263  0.029056  Leptodactylidae  Adenomera   \n",
       "2    -0.025083  0.099108  0.077162  Leptodactylidae  Adenomera   \n",
       "3    -0.054766 -0.018691  0.023954  Leptodactylidae  Adenomera   \n",
       "4    -0.031346  0.108610  0.079244  Leptodactylidae  Adenomera   \n",
       "...        ...       ...       ...              ...        ...   \n",
       "7190  0.052449 -0.021860 -0.079860          Hylidae     Scinax   \n",
       "7191  0.046461 -0.015418 -0.101892          Hylidae     Scinax   \n",
       "7192  0.027834 -0.000531 -0.080425          Hylidae     Scinax   \n",
       "7193  0.041803 -0.027911 -0.096895          Hylidae     Scinax   \n",
       "7194  0.031560 -0.029355 -0.087910          Hylidae     Scinax   \n",
       "\n",
       "             Species  RecordID  \n",
       "0     AdenomeraAndre         1  \n",
       "1     AdenomeraAndre         1  \n",
       "2     AdenomeraAndre         1  \n",
       "3     AdenomeraAndre         1  \n",
       "4     AdenomeraAndre         1  \n",
       "...              ...       ...  \n",
       "7190     ScinaxRuber        60  \n",
       "7191     ScinaxRuber        60  \n",
       "7192     ScinaxRuber        60  \n",
       "7193     ScinaxRuber        60  \n",
       "7194     ScinaxRuber        60  \n",
       "\n",
       "[7195 rows x 26 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_data = \"../data/Frogs_MFCCs.csv\"\n",
    "mfcc_data = pd.read_csv(mfcc_data)\n",
    "mfcc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fb00495",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_row = len(mfcc_data)\n",
    "random.seed(num_row)\n",
    "\n",
    "shuffled_rows = range(num_row)\n",
    "_70_percent_trainx = int(num_row * 0.7)\n",
    "train_idx = random.sample(shuffled_rows, _70_percent_trainx)\n",
    "\n",
    "test_idx = []\n",
    "for i in range(num_row):\n",
    "    if i not in train_idx:\n",
    "        test_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9338b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Leptodactylidae    4420\n",
       "Hylidae            2165\n",
       "Dendrobatidae       542\n",
       "Bufonidae            68\n",
       "Name: Family, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_data['Family'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6463bcdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adenomera        4150\n",
       "Hypsiboas        1593\n",
       "Ameerega          542\n",
       "Dendropsophus     310\n",
       "Leptodactylus     270\n",
       "Scinax            148\n",
       "Osteocephalus     114\n",
       "Rhinella           68\n",
       "Name: Genus, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_data['Genus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3be15c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdenomeraHylaedactylus    3478\n",
       "HypsiboasCordobae         1121\n",
       "AdenomeraAndre             672\n",
       "Ameeregatrivittata         542\n",
       "HypsiboasCinerascens       472\n",
       "HylaMinuta                 310\n",
       "LeptodactylusFuscus        270\n",
       "ScinaxRuber                148\n",
       "OsteocephalusOophagus      114\n",
       "Rhinellagranulosa           68\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_data['Species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "340af385",
   "metadata": {},
   "outputs": [],
   "source": [
    "family = mfcc_data['Family']\n",
    "genus = mfcc_data['Genus']\n",
    "species = mfcc_data['Species']\n",
    "\n",
    "# split train and test\n",
    "mfcc_train = mfcc_data.iloc[train_idx, :].reset_index(drop=True)\n",
    "mfcc_test = mfcc_data.iloc[test_idx, :].reset_index(drop=True)\n",
    "\n",
    "# split train features and labels\n",
    "train_x = mfcc_train.iloc[:, :-4]\n",
    "train_family = mfcc_train['Family']\n",
    "train_genus = mfcc_train['Genus']\n",
    "train_species = mfcc_train['Species']\n",
    "\n",
    "# split test features and labels\n",
    "test_x = mfcc_test.iloc[:, :-4]\n",
    "test_family = mfcc_test['Family']\n",
    "test_genus = mfcc_test['Genus']\n",
    "test_species = mfcc_test['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23195eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5036, 26)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8b0cf2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2159, 26)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f547c36",
   "metadata": {},
   "source": [
    "**1(b). Each instance has three labels: Families, Genus, and Species. Each of the labels has multiple classes. We wish to solve a multi-class and multi-label problem. One of the most important approaches to multi-label classification is to train a classifier for each label (binary relevance). We first try this approach:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e94314c",
   "metadata": {},
   "source": [
    "***1(b)-i. Research exact match and hamming score/ loss methods for evaluating multi-label classification and use them in evaluating the classifiers in this problem.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9772d392",
   "metadata": {},
   "source": [
    "- An exact match is achieved for a specific example if and only if the model's predicted labels are identical to the true labels for that example. In other words, the model correctly identifies all the relevant labels without making any mistakes. The exact match metric provides a binary assessment of whether the model's predictions match the ground truth labels for each example. \n",
    "- Hamming Loss measures the average fraction of labels that are incorrectly predicted by the model for a set of examples. In other words, it quantifies the difference between the true labels and the predicted labels on a per-example basis and then averages this difference across all examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36241fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Multi_Label(groundTruthY, predictY):\n",
    "    #Hamming Loss\n",
    "    misslassifiedLabels = 0\n",
    "    for truth, pred in zip(groundTruthY.values, predictY.values):\n",
    "        miss = (truth != pred)\n",
    "        misslassifiedLabels += np.sum(miss)\n",
    "    print(f'groundTruthY.shape[0] : {groundTruthY.shape[0]}')\n",
    "    print(f'groundTruthY.shape[1] : {groundTruthY.shape[1]}')\n",
    "    hamming_score = misslassifiedLabels / (groundTruthY.shape[0] * groundTruthY.shape[1])\n",
    "    \n",
    "    #Exact Match Ratio\n",
    "    exactMatchRatio = 0\n",
    "    for truth, pred in zip(groundTruthY.values, predictY.values):\n",
    "        match = (truth == pred)\n",
    "        if sum(match) == groundTruthY.shape[1]:\n",
    "            exactMatchRatio += 1;\n",
    "    exactMatchRatio /= groundTruthY.shape[0]\n",
    "    \n",
    "    hamming_score = np.round(hamming_score, 4)\n",
    "    exactMatchRatio = np.round(exactMatchRatio, 4)\n",
    "    \n",
    "    ans = {\n",
    "        \"Hamming Loss\": [hamming_score],\n",
    "        \"Exact Match Ratio\": [exactMatchRatio]\n",
    "    }\n",
    "    print(pd.DataFrame(data=ans))\n",
    "    return hamming_score, exactMatchRatio\n",
    "\n",
    "def multilabelEval(title, testX, groundTruthY, classifiers):\n",
    "    predictY = pd.DataFrame(columns=groundTruthY.columns)\n",
    "    for label in groundTruthY.columns:\n",
    "        clf = classifiers[label]\n",
    "        test_pred = clf.predict(testX)\n",
    "        predictY.loc[:, label] = test_pred\n",
    "    print(f\"Multilabel evaluation of {title}\")\n",
    "    hamming_score, exactMatchRatio = Multi_Label(groundTruthY, predictY)\n",
    "    return [hamming_score, exactMatchRatio]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63387163",
   "metadata": {},
   "source": [
    "***1(b)-ii. Train a SVM for each of the labels, using Gaussian kernels and one versus all classifiers. Determine the weight of the SVM penalty and the width of the Gaussian Kernel using 10 fold cross validation. You are welcome to try to solve the problem with both standardized and raw attributes and report the results.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdbe5d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Family (Gaussian SVC without Standardization)\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Grid scores on development set:\n",
      "\n",
      "0.869 (+/-0.019) for {'C': 10.0, 'gamma': 0.001}\n",
      "0.926 (+/-0.016) for {'C': 10.0, 'gamma': 0.01}\n",
      "0.971 (+/-0.012) for {'C': 10.0, 'gamma': 0.1}\n",
      "0.991 (+/-0.007) for {'C': 10.0, 'gamma': 1.0}\n",
      "0.986 (+/-0.01) for {'C': 10.0, 'gamma': 10.0}\n",
      "0.791 (+/-0.04) for {'C': 10.0, 'gamma': 100.0}\n",
      "0.492 (+/-0.021) for {'C': 10.0, 'gamma': 1000.0}\n",
      "0.472 (+/-0.005) for {'C': 10.0, 'gamma': 10000.0}\n",
      "0.47 (+/-0.002) for {'C': 10.0, 'gamma': 100000.0}\n",
      "0.47 (+/-0.002) for {'C': 10.0, 'gamma': 1000000.0}\n",
      "0.925 (+/-0.016) for {'C': 100.0, 'gamma': 0.001}\n",
      "0.94 (+/-0.02) for {'C': 100.0, 'gamma': 0.01}\n",
      "0.982 (+/-0.007) for {'C': 100.0, 'gamma': 0.1}\n",
      "0.992 (+/-0.008) for {'C': 100.0, 'gamma': 1.0}\n",
      "0.986 (+/-0.01) for {'C': 100.0, 'gamma': 10.0}\n",
      "0.791 (+/-0.04) for {'C': 100.0, 'gamma': 100.0}\n",
      "0.492 (+/-0.021) for {'C': 100.0, 'gamma': 1000.0}\n",
      "0.472 (+/-0.005) for {'C': 100.0, 'gamma': 10000.0}\n",
      "0.47 (+/-0.002) for {'C': 100.0, 'gamma': 100000.0}\n",
      "0.47 (+/-0.002) for {'C': 100.0, 'gamma': 1000000.0}\n",
      "0.937 (+/-0.02) for {'C': 1000.0, 'gamma': 0.001}\n",
      "0.971 (+/-0.013) for {'C': 1000.0, 'gamma': 0.01}\n",
      "0.986 (+/-0.006) for {'C': 1000.0, 'gamma': 0.1}\n",
      "0.991 (+/-0.008) for {'C': 1000.0, 'gamma': 1.0}\n",
      "0.986 (+/-0.01) for {'C': 1000.0, 'gamma': 10.0}\n",
      "0.791 (+/-0.04) for {'C': 1000.0, 'gamma': 100.0}\n",
      "0.492 (+/-0.021) for {'C': 1000.0, 'gamma': 1000.0}\n",
      "0.472 (+/-0.005) for {'C': 1000.0, 'gamma': 10000.0}\n",
      "0.47 (+/-0.002) for {'C': 1000.0, 'gamma': 100000.0}\n",
      "0.47 (+/-0.002) for {'C': 1000.0, 'gamma': 1000000.0}\n",
      "0.954 (+/-0.019) for {'C': 10000.0, 'gamma': 0.001}\n",
      "0.98 (+/-0.008) for {'C': 10000.0, 'gamma': 0.01}\n",
      "0.986 (+/-0.013) for {'C': 10000.0, 'gamma': 0.1}\n",
      "0.991 (+/-0.008) for {'C': 10000.0, 'gamma': 1.0}\n",
      "0.986 (+/-0.01) for {'C': 10000.0, 'gamma': 10.0}\n",
      "0.791 (+/-0.04) for {'C': 10000.0, 'gamma': 100.0}\n",
      "0.492 (+/-0.021) for {'C': 10000.0, 'gamma': 1000.0}\n",
      "0.472 (+/-0.005) for {'C': 10000.0, 'gamma': 10000.0}\n",
      "0.47 (+/-0.002) for {'C': 10000.0, 'gamma': 100000.0}\n",
      "0.47 (+/-0.002) for {'C': 10000.0, 'gamma': 1000000.0}\n",
      "\n",
      "The best parameter setting is:\n",
      "{'C': 100.0, 'gamma': 1.0} \n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Bufonidae       0.93      0.93      0.93        15\n",
      "  Dendrobatidae       0.99      0.99      0.99       154\n",
      "        Hylidae       0.99      0.98      0.99       673\n",
      "Leptodactylidae       0.99      1.00      0.99      1317\n",
      "\n",
      "       accuracy                           0.99      2159\n",
      "      macro avg       0.98      0.98      0.98      2159\n",
      "   weighted avg       0.99      0.99      0.99      2159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def paramGridSearch(classifier, kwargs, trainX, trainY, testX, testY):\n",
    "    classifier = GridSearchCV(estimator=classifier, **kwargs)\n",
    "    classifier.fit(trainX, trainY)\n",
    "    \n",
    "    print(\"Grid scores on development set:\\n\")\n",
    "    means = classifier.cv_results_['mean_test_score']\n",
    "    stds = classifier.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, classifier.cv_results_['params']):\n",
    "        print(f\"{round(mean, 3)} (+/-{round(std * 2, 3)}) for {params}\")\n",
    "    \n",
    "    print(\"\\nThe best parameter setting is:\")\n",
    "    print(classifier.best_params_, \"\\n\")\n",
    "    \n",
    "    test_pred = classifier.predict(testX)\n",
    "    print(classification_report(testY, test_pred))\n",
    "    return classifier\n",
    "\n",
    "# Gaussian SVC without standardization\n",
    "gaussianSVC_classifiers = {}\n",
    "tuned_params = {'C' : np.logspace(1, 4, 4), \n",
    "                'gamma' : np.logspace(-3, 6, 10)}\n",
    "splitter = StratifiedKFold(10, random_state=5036, shuffle=True)\n",
    "kwargs = {'param_grid' : tuned_params, 'cv' : splitter, 'scoring' : 'f1_weighted', 'verbose' : 1}\n",
    "\n",
    "print(f\"Class: Family (Gaussian SVC without Standardization)\")\n",
    "gaussianSVC_classifiers['Family'] = paramGridSearch(SVC(kernel='rbf'), kwargs, train_x, \n",
    "                                                    train_family, test_x, test_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae616ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Genus (Gaussian SVC without Standardization)\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Grid scores on development set:\n",
      "\n",
      "0.744 (+/-0.026) for {'C': 10.0, 'gamma': 0.001}\n",
      "0.92 (+/-0.019) for {'C': 10.0, 'gamma': 0.01}\n",
      "0.973 (+/-0.014) for {'C': 10.0, 'gamma': 0.1}\n",
      "0.988 (+/-0.009) for {'C': 10.0, 'gamma': 1.0}\n",
      "0.98 (+/-0.011) for {'C': 10.0, 'gamma': 10.0}\n",
      "0.733 (+/-0.042) for {'C': 10.0, 'gamma': 100.0}\n",
      "0.442 (+/-0.014) for {'C': 10.0, 'gamma': 1000.0}\n",
      "0.425 (+/-0.004) for {'C': 10.0, 'gamma': 10000.0}\n",
      "0.423 (+/-0.001) for {'C': 10.0, 'gamma': 100000.0}\n",
      "0.423 (+/-0.001) for {'C': 10.0, 'gamma': 1000000.0}\n",
      "0.919 (+/-0.017) for {'C': 100.0, 'gamma': 0.001}\n",
      "0.965 (+/-0.016) for {'C': 100.0, 'gamma': 0.01}\n",
      "0.985 (+/-0.009) for {'C': 100.0, 'gamma': 0.1}\n",
      "0.989 (+/-0.007) for {'C': 100.0, 'gamma': 1.0}\n",
      "0.98 (+/-0.011) for {'C': 100.0, 'gamma': 10.0}\n",
      "0.733 (+/-0.042) for {'C': 100.0, 'gamma': 100.0}\n",
      "0.442 (+/-0.014) for {'C': 100.0, 'gamma': 1000.0}\n",
      "0.425 (+/-0.004) for {'C': 100.0, 'gamma': 10000.0}\n",
      "0.423 (+/-0.001) for {'C': 100.0, 'gamma': 100000.0}\n",
      "0.423 (+/-0.001) for {'C': 100.0, 'gamma': 1000000.0}\n",
      "0.962 (+/-0.02) for {'C': 1000.0, 'gamma': 0.001}\n",
      "0.974 (+/-0.015) for {'C': 1000.0, 'gamma': 0.01}\n",
      "0.988 (+/-0.011) for {'C': 1000.0, 'gamma': 0.1}\n",
      "0.989 (+/-0.007) for {'C': 1000.0, 'gamma': 1.0}\n",
      "0.98 (+/-0.011) for {'C': 1000.0, 'gamma': 10.0}\n",
      "0.733 (+/-0.042) for {'C': 1000.0, 'gamma': 100.0}\n",
      "0.442 (+/-0.014) for {'C': 1000.0, 'gamma': 1000.0}\n",
      "0.425 (+/-0.004) for {'C': 1000.0, 'gamma': 10000.0}\n",
      "0.423 (+/-0.001) for {'C': 1000.0, 'gamma': 100000.0}\n",
      "0.423 (+/-0.001) for {'C': 1000.0, 'gamma': 1000000.0}\n",
      "0.971 (+/-0.011) for {'C': 10000.0, 'gamma': 0.001}\n",
      "0.983 (+/-0.014) for {'C': 10000.0, 'gamma': 0.01}\n",
      "0.987 (+/-0.009) for {'C': 10000.0, 'gamma': 0.1}\n",
      "0.989 (+/-0.007) for {'C': 10000.0, 'gamma': 1.0}\n",
      "0.98 (+/-0.011) for {'C': 10000.0, 'gamma': 10.0}\n",
      "0.733 (+/-0.042) for {'C': 10000.0, 'gamma': 100.0}\n",
      "0.442 (+/-0.014) for {'C': 10000.0, 'gamma': 1000.0}\n",
      "0.425 (+/-0.004) for {'C': 10000.0, 'gamma': 10000.0}\n",
      "0.423 (+/-0.001) for {'C': 10000.0, 'gamma': 100000.0}\n",
      "0.423 (+/-0.001) for {'C': 10000.0, 'gamma': 1000000.0}\n",
      "\n",
      "The best parameter setting is:\n",
      "{'C': 100.0, 'gamma': 1.0} \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Adenomera       0.99      1.00      1.00      1240\n",
      "     Ameerega       0.99      0.99      0.99       154\n",
      "Dendropsophus       0.97      0.95      0.96        91\n",
      "    Hypsiboas       0.99      0.99      0.99       479\n",
      "Leptodactylus       0.95      1.00      0.97        77\n",
      "Osteocephalus       1.00      0.87      0.93        47\n",
      "     Rhinella       1.00      0.93      0.97        15\n",
      "       Scinax       1.00      0.98      0.99        56\n",
      "\n",
      "     accuracy                           0.99      2159\n",
      "    macro avg       0.99      0.96      0.97      2159\n",
      " weighted avg       0.99      0.99      0.99      2159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Class: Genus (Gaussian SVC without Standardization)\")\n",
    "gaussianSVC_classifiers['Genus'] = paramGridSearch(SVC(kernel='rbf'), kwargs, train_x, train_genus, test_x, test_genus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "824257fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Species (Gaussian SVC without Standardization)\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Grid scores on development set:\n",
      "\n",
      "0.8 (+/-0.015) for {'C': 10.0, 'gamma': 0.001}\n",
      "0.935 (+/-0.021) for {'C': 10.0, 'gamma': 0.01}\n",
      "0.974 (+/-0.017) for {'C': 10.0, 'gamma': 0.1}\n",
      "0.988 (+/-0.011) for {'C': 10.0, 'gamma': 1.0}\n",
      "0.978 (+/-0.01) for {'C': 10.0, 'gamma': 10.0}\n",
      "0.656 (+/-0.04) for {'C': 10.0, 'gamma': 100.0}\n",
      "0.33 (+/-0.015) for {'C': 10.0, 'gamma': 1000.0}\n",
      "0.314 (+/-0.005) for {'C': 10.0, 'gamma': 10000.0}\n",
      "0.312 (+/-0.001) for {'C': 10.0, 'gamma': 100000.0}\n",
      "0.312 (+/-0.001) for {'C': 10.0, 'gamma': 1000000.0}\n",
      "0.935 (+/-0.021) for {'C': 100.0, 'gamma': 0.001}\n",
      "0.97 (+/-0.018) for {'C': 100.0, 'gamma': 0.01}\n",
      "0.985 (+/-0.019) for {'C': 100.0, 'gamma': 0.1}\n",
      "0.988 (+/-0.011) for {'C': 100.0, 'gamma': 1.0}\n",
      "0.978 (+/-0.01) for {'C': 100.0, 'gamma': 10.0}\n",
      "0.656 (+/-0.04) for {'C': 100.0, 'gamma': 100.0}\n",
      "0.33 (+/-0.015) for {'C': 100.0, 'gamma': 1000.0}\n",
      "0.314 (+/-0.005) for {'C': 100.0, 'gamma': 10000.0}\n",
      "0.312 (+/-0.001) for {'C': 100.0, 'gamma': 100000.0}\n",
      "0.312 (+/-0.001) for {'C': 100.0, 'gamma': 1000000.0}\n",
      "0.969 (+/-0.019) for {'C': 1000.0, 'gamma': 0.001}\n",
      "0.979 (+/-0.017) for {'C': 1000.0, 'gamma': 0.01}\n",
      "0.986 (+/-0.013) for {'C': 1000.0, 'gamma': 0.1}\n",
      "0.988 (+/-0.011) for {'C': 1000.0, 'gamma': 1.0}\n",
      "0.978 (+/-0.01) for {'C': 1000.0, 'gamma': 10.0}\n",
      "0.656 (+/-0.04) for {'C': 1000.0, 'gamma': 100.0}\n",
      "0.33 (+/-0.015) for {'C': 1000.0, 'gamma': 1000.0}\n",
      "0.314 (+/-0.005) for {'C': 1000.0, 'gamma': 10000.0}\n",
      "0.312 (+/-0.001) for {'C': 1000.0, 'gamma': 100000.0}\n",
      "0.312 (+/-0.001) for {'C': 1000.0, 'gamma': 1000000.0}\n",
      "0.978 (+/-0.015) for {'C': 10000.0, 'gamma': 0.001}\n",
      "0.981 (+/-0.017) for {'C': 10000.0, 'gamma': 0.01}\n",
      "0.985 (+/-0.013) for {'C': 10000.0, 'gamma': 0.1}\n",
      "0.988 (+/-0.011) for {'C': 10000.0, 'gamma': 1.0}\n",
      "0.978 (+/-0.01) for {'C': 10000.0, 'gamma': 10.0}\n",
      "0.656 (+/-0.04) for {'C': 10000.0, 'gamma': 100.0}\n",
      "0.33 (+/-0.015) for {'C': 10000.0, 'gamma': 1000.0}\n",
      "0.314 (+/-0.005) for {'C': 10000.0, 'gamma': 10000.0}\n",
      "0.312 (+/-0.001) for {'C': 10000.0, 'gamma': 100000.0}\n",
      "0.312 (+/-0.001) for {'C': 10000.0, 'gamma': 1000000.0}\n",
      "\n",
      "The best parameter setting is:\n",
      "{'C': 100.0, 'gamma': 1.0} \n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        AdenomeraAndre       0.99      0.98      0.99       182\n",
      "AdenomeraHylaedactylus       0.99      1.00      1.00      1058\n",
      "    Ameeregatrivittata       0.98      0.99      0.99       154\n",
      "            HylaMinuta       0.97      0.95      0.96        91\n",
      "  HypsiboasCinerascens       0.98      0.99      0.99       153\n",
      "     HypsiboasCordobae       0.99      0.98      0.99       326\n",
      "   LeptodactylusFuscus       0.97      1.00      0.99        77\n",
      " OsteocephalusOophagus       0.98      0.89      0.93        47\n",
      "     Rhinellagranulosa       1.00      0.93      0.97        15\n",
      "           ScinaxRuber       1.00      0.98      0.99        56\n",
      "\n",
      "              accuracy                           0.99      2159\n",
      "             macro avg       0.99      0.97      0.98      2159\n",
      "          weighted avg       0.99      0.99      0.99      2159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Class: Species (Gaussian SVC without Standardization)\")\n",
    "gaussianSVC_classifiers['Species'] = paramGridSearch(SVC(kernel='rbf'), kwargs, train_x, \n",
    "                                                     train_species, test_x, test_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41c3e03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilabel evaluation of Gaussian SVC without Standardization\n",
      "groundTruthY.shape[0] : 2159\n",
      "groundTruthY.shape[1] : 3\n",
      "   Hamming Loss  Exact Match Ratio\n",
      "0        0.0096             0.9852\n"
     ]
    }
   ],
   "source": [
    "title = \"Gaussian SVC without Standardization\"\n",
    "summary = {}\n",
    "summary[title] = multilabelEval(title, test_x, mfcc_test.iloc[:, -4:-1], gaussianSVC_classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59b23c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to standardize the attributes\n"
     ]
    }
   ],
   "source": [
    "print(\"Attempting to standardize the attributes\")\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "std_train_x = std_scaler.fit_transform(train_x)\n",
    "std_test_x = std_scaler.fit_transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1abbd447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Family (Gaussian SVC with Standardization)\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Grid scores on development set:\n",
      "\n",
      "0.944 (+/-0.02) for {'C': 10.0, 'gamma': 0.001}\n",
      "0.987 (+/-0.005) for {'C': 10.0, 'gamma': 0.01}\n",
      "0.99 (+/-0.007) for {'C': 10.0, 'gamma': 0.1}\n",
      "0.905 (+/-0.023) for {'C': 10.0, 'gamma': 1.0}\n",
      "0.575 (+/-0.047) for {'C': 10.0, 'gamma': 10.0}\n",
      "0.473 (+/-0.004) for {'C': 10.0, 'gamma': 100.0}\n",
      "0.47 (+/-0.002) for {'C': 10.0, 'gamma': 1000.0}\n",
      "0.47 (+/-0.002) for {'C': 10.0, 'gamma': 10000.0}\n",
      "0.47 (+/-0.002) for {'C': 10.0, 'gamma': 100000.0}\n",
      "0.47 (+/-0.002) for {'C': 10.0, 'gamma': 1000000.0}\n",
      "0.975 (+/-0.013) for {'C': 100.0, 'gamma': 0.001}\n",
      "0.989 (+/-0.007) for {'C': 100.0, 'gamma': 0.01}\n",
      "0.99 (+/-0.007) for {'C': 100.0, 'gamma': 0.1}\n",
      "0.905 (+/-0.023) for {'C': 100.0, 'gamma': 1.0}\n",
      "0.575 (+/-0.047) for {'C': 100.0, 'gamma': 10.0}\n",
      "0.473 (+/-0.004) for {'C': 100.0, 'gamma': 100.0}\n",
      "0.47 (+/-0.002) for {'C': 100.0, 'gamma': 1000.0}\n",
      "0.47 (+/-0.002) for {'C': 100.0, 'gamma': 10000.0}\n",
      "0.47 (+/-0.002) for {'C': 100.0, 'gamma': 100000.0}\n",
      "0.47 (+/-0.002) for {'C': 100.0, 'gamma': 1000000.0}\n",
      "0.983 (+/-0.007) for {'C': 1000.0, 'gamma': 0.001}\n",
      "0.989 (+/-0.008) for {'C': 1000.0, 'gamma': 0.01}\n",
      "0.99 (+/-0.007) for {'C': 1000.0, 'gamma': 0.1}\n",
      "0.905 (+/-0.023) for {'C': 1000.0, 'gamma': 1.0}\n",
      "0.575 (+/-0.047) for {'C': 1000.0, 'gamma': 10.0}\n",
      "0.473 (+/-0.004) for {'C': 1000.0, 'gamma': 100.0}\n",
      "0.47 (+/-0.002) for {'C': 1000.0, 'gamma': 1000.0}\n",
      "0.47 (+/-0.002) for {'C': 1000.0, 'gamma': 10000.0}\n",
      "0.47 (+/-0.002) for {'C': 1000.0, 'gamma': 100000.0}\n",
      "0.47 (+/-0.002) for {'C': 1000.0, 'gamma': 1000000.0}\n",
      "0.985 (+/-0.008) for {'C': 10000.0, 'gamma': 0.001}\n",
      "0.989 (+/-0.008) for {'C': 10000.0, 'gamma': 0.01}\n",
      "0.99 (+/-0.007) for {'C': 10000.0, 'gamma': 0.1}\n",
      "0.905 (+/-0.023) for {'C': 10000.0, 'gamma': 1.0}\n",
      "0.575 (+/-0.047) for {'C': 10000.0, 'gamma': 10.0}\n",
      "0.473 (+/-0.004) for {'C': 10000.0, 'gamma': 100.0}\n",
      "0.47 (+/-0.002) for {'C': 10000.0, 'gamma': 1000.0}\n",
      "0.47 (+/-0.002) for {'C': 10000.0, 'gamma': 10000.0}\n",
      "0.47 (+/-0.002) for {'C': 10000.0, 'gamma': 100000.0}\n",
      "0.47 (+/-0.002) for {'C': 10000.0, 'gamma': 1000000.0}\n",
      "\n",
      "The best parameter setting is:\n",
      "{'C': 10.0, 'gamma': 0.1} \n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Bufonidae       1.00      0.93      0.97        15\n",
      "  Dendrobatidae       1.00      1.00      1.00       154\n",
      "        Hylidae       0.98      1.00      0.99       673\n",
      "Leptodactylidae       1.00      0.99      0.99      1317\n",
      "\n",
      "       accuracy                           0.99      2159\n",
      "      macro avg       1.00      0.98      0.99      2159\n",
      "   weighted avg       0.99      0.99      0.99      2159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Class: Family (Gaussian SVC with Standardization)\")\n",
    "gaussianSVC_classifiers['Family'] = paramGridSearch(SVC(kernel='rbf'), kwargs, std_train_x, \n",
    "                                                    train_family, std_test_x, test_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c86c3344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Genus (Gaussian SVC with Standardization)\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Grid scores on development set:\n",
      "\n",
      "0.958 (+/-0.018) for {'C': 10.0, 'gamma': 0.001}\n",
      "0.986 (+/-0.008) for {'C': 10.0, 'gamma': 0.01}\n",
      "0.987 (+/-0.009) for {'C': 10.0, 'gamma': 0.1}\n",
      "0.857 (+/-0.02) for {'C': 10.0, 'gamma': 1.0}\n",
      "0.513 (+/-0.018) for {'C': 10.0, 'gamma': 10.0}\n",
      "0.426 (+/-0.006) for {'C': 10.0, 'gamma': 100.0}\n",
      "0.423 (+/-0.001) for {'C': 10.0, 'gamma': 1000.0}\n",
      "0.423 (+/-0.001) for {'C': 10.0, 'gamma': 10000.0}\n",
      "0.423 (+/-0.001) for {'C': 10.0, 'gamma': 100000.0}\n",
      "0.423 (+/-0.001) for {'C': 10.0, 'gamma': 1000000.0}\n",
      "0.977 (+/-0.013) for {'C': 100.0, 'gamma': 0.001}\n",
      "0.988 (+/-0.008) for {'C': 100.0, 'gamma': 0.01}\n",
      "0.987 (+/-0.009) for {'C': 100.0, 'gamma': 0.1}\n",
      "0.857 (+/-0.02) for {'C': 100.0, 'gamma': 1.0}\n",
      "0.513 (+/-0.018) for {'C': 100.0, 'gamma': 10.0}\n",
      "0.426 (+/-0.006) for {'C': 100.0, 'gamma': 100.0}\n",
      "0.423 (+/-0.001) for {'C': 100.0, 'gamma': 1000.0}\n",
      "0.423 (+/-0.001) for {'C': 100.0, 'gamma': 10000.0}\n",
      "0.423 (+/-0.001) for {'C': 100.0, 'gamma': 100000.0}\n",
      "0.423 (+/-0.001) for {'C': 100.0, 'gamma': 1000000.0}\n",
      "0.985 (+/-0.007) for {'C': 1000.0, 'gamma': 0.001}\n",
      "0.987 (+/-0.007) for {'C': 1000.0, 'gamma': 0.01}\n",
      "0.987 (+/-0.009) for {'C': 1000.0, 'gamma': 0.1}\n",
      "0.857 (+/-0.02) for {'C': 1000.0, 'gamma': 1.0}\n",
      "0.513 (+/-0.018) for {'C': 1000.0, 'gamma': 10.0}\n",
      "0.426 (+/-0.006) for {'C': 1000.0, 'gamma': 100.0}\n",
      "0.423 (+/-0.001) for {'C': 1000.0, 'gamma': 1000.0}\n",
      "0.423 (+/-0.001) for {'C': 1000.0, 'gamma': 10000.0}\n",
      "0.423 (+/-0.001) for {'C': 1000.0, 'gamma': 100000.0}\n",
      "0.423 (+/-0.001) for {'C': 1000.0, 'gamma': 1000000.0}\n",
      "0.984 (+/-0.012) for {'C': 10000.0, 'gamma': 0.001}\n",
      "0.987 (+/-0.007) for {'C': 10000.0, 'gamma': 0.01}\n",
      "0.987 (+/-0.009) for {'C': 10000.0, 'gamma': 0.1}\n",
      "0.857 (+/-0.02) for {'C': 10000.0, 'gamma': 1.0}\n",
      "0.513 (+/-0.018) for {'C': 10000.0, 'gamma': 10.0}\n",
      "0.426 (+/-0.006) for {'C': 10000.0, 'gamma': 100.0}\n",
      "0.423 (+/-0.001) for {'C': 10000.0, 'gamma': 1000.0}\n",
      "0.423 (+/-0.001) for {'C': 10000.0, 'gamma': 10000.0}\n",
      "0.423 (+/-0.001) for {'C': 10000.0, 'gamma': 100000.0}\n",
      "0.423 (+/-0.001) for {'C': 10000.0, 'gamma': 1000000.0}\n",
      "\n",
      "The best parameter setting is:\n",
      "{'C': 100.0, 'gamma': 0.01} \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Adenomera       0.99      1.00      0.99      1240\n",
      "     Ameerega       0.99      0.99      0.99       154\n",
      "Dendropsophus       0.96      0.95      0.95        91\n",
      "    Hypsiboas       0.98      0.98      0.98       479\n",
      "Leptodactylus       0.96      0.99      0.97        77\n",
      "Osteocephalus       1.00      0.85      0.92        47\n",
      "     Rhinella       0.88      1.00      0.94        15\n",
      "       Scinax       1.00      0.96      0.98        56\n",
      "\n",
      "     accuracy                           0.99      2159\n",
      "    macro avg       0.97      0.96      0.97      2159\n",
      " weighted avg       0.99      0.99      0.99      2159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Class: Genus (Gaussian SVC with Standardization)\")\n",
    "gaussianSVC_classifiers['Genus'] = paramGridSearch(SVC(kernel='rbf'), kwargs, std_train_x, \n",
    "                                                   train_genus, std_test_x, test_genus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5e53f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Species (Gaussian SVC with Standardization)\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Grid scores on development set:\n",
      "\n",
      "0.967 (+/-0.018) for {'C': 10.0, 'gamma': 0.001}\n",
      "0.987 (+/-0.013) for {'C': 10.0, 'gamma': 0.01}\n",
      "0.985 (+/-0.008) for {'C': 10.0, 'gamma': 0.1}\n",
      "0.835 (+/-0.024) for {'C': 10.0, 'gamma': 1.0}\n",
      "0.389 (+/-0.026) for {'C': 10.0, 'gamma': 10.0}\n",
      "0.315 (+/-0.006) for {'C': 10.0, 'gamma': 100.0}\n",
      "0.312 (+/-0.001) for {'C': 10.0, 'gamma': 1000.0}\n",
      "0.312 (+/-0.001) for {'C': 10.0, 'gamma': 10000.0}\n",
      "0.312 (+/-0.001) for {'C': 10.0, 'gamma': 100000.0}\n",
      "0.312 (+/-0.001) for {'C': 10.0, 'gamma': 1000000.0}\n",
      "0.98 (+/-0.014) for {'C': 100.0, 'gamma': 0.001}\n",
      "0.987 (+/-0.012) for {'C': 100.0, 'gamma': 0.01}\n",
      "0.985 (+/-0.008) for {'C': 100.0, 'gamma': 0.1}\n",
      "0.835 (+/-0.024) for {'C': 100.0, 'gamma': 1.0}\n",
      "0.389 (+/-0.026) for {'C': 100.0, 'gamma': 10.0}\n",
      "0.315 (+/-0.006) for {'C': 100.0, 'gamma': 100.0}\n",
      "0.312 (+/-0.001) for {'C': 100.0, 'gamma': 1000.0}\n",
      "0.312 (+/-0.001) for {'C': 100.0, 'gamma': 10000.0}\n",
      "0.312 (+/-0.001) for {'C': 100.0, 'gamma': 100000.0}\n",
      "0.312 (+/-0.001) for {'C': 100.0, 'gamma': 1000000.0}\n",
      "0.983 (+/-0.015) for {'C': 1000.0, 'gamma': 0.001}\n",
      "0.987 (+/-0.013) for {'C': 1000.0, 'gamma': 0.01}\n",
      "0.985 (+/-0.008) for {'C': 1000.0, 'gamma': 0.1}\n",
      "0.835 (+/-0.024) for {'C': 1000.0, 'gamma': 1.0}\n",
      "0.389 (+/-0.026) for {'C': 1000.0, 'gamma': 10.0}\n",
      "0.315 (+/-0.006) for {'C': 1000.0, 'gamma': 100.0}\n",
      "0.312 (+/-0.001) for {'C': 1000.0, 'gamma': 1000.0}\n",
      "0.312 (+/-0.001) for {'C': 1000.0, 'gamma': 10000.0}\n",
      "0.312 (+/-0.001) for {'C': 1000.0, 'gamma': 100000.0}\n",
      "0.312 (+/-0.001) for {'C': 1000.0, 'gamma': 1000000.0}\n",
      "0.983 (+/-0.014) for {'C': 10000.0, 'gamma': 0.001}\n",
      "0.987 (+/-0.013) for {'C': 10000.0, 'gamma': 0.01}\n",
      "0.985 (+/-0.008) for {'C': 10000.0, 'gamma': 0.1}\n",
      "0.835 (+/-0.024) for {'C': 10000.0, 'gamma': 1.0}\n",
      "0.389 (+/-0.026) for {'C': 10000.0, 'gamma': 10.0}\n",
      "0.315 (+/-0.006) for {'C': 10000.0, 'gamma': 100.0}\n",
      "0.312 (+/-0.001) for {'C': 10000.0, 'gamma': 1000.0}\n",
      "0.312 (+/-0.001) for {'C': 10000.0, 'gamma': 10000.0}\n",
      "0.312 (+/-0.001) for {'C': 10000.0, 'gamma': 100000.0}\n",
      "0.312 (+/-0.001) for {'C': 10000.0, 'gamma': 1000000.0}\n",
      "\n",
      "The best parameter setting is:\n",
      "{'C': 100.0, 'gamma': 0.01} \n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        AdenomeraAndre       0.98      0.98      0.98       182\n",
      "AdenomeraHylaedactylus       0.99      1.00      1.00      1058\n",
      "    Ameeregatrivittata       0.99      0.99      0.99       154\n",
      "            HylaMinuta       0.94      0.93      0.94        91\n",
      "  HypsiboasCinerascens       0.97      0.99      0.98       153\n",
      "     HypsiboasCordobae       0.99      0.98      0.99       326\n",
      "   LeptodactylusFuscus       0.97      0.99      0.98        77\n",
      " OsteocephalusOophagus       0.95      0.89      0.92        47\n",
      "     Rhinellagranulosa       0.88      1.00      0.94        15\n",
      "           ScinaxRuber       1.00      0.98      0.99        56\n",
      "\n",
      "              accuracy                           0.99      2159\n",
      "             macro avg       0.97      0.97      0.97      2159\n",
      "          weighted avg       0.99      0.99      0.99      2159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Class: Species (Gaussian SVC with Standardization)\")\n",
    "gaussianSVC_classifiers['Species'] = paramGridSearch(SVC(kernel='rbf'), kwargs, std_train_x, \n",
    "                                                     train_species, std_test_x, test_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d73aa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilabel evaluation of Gaussian SVC Standardization\n",
      "groundTruthY.shape[0] : 2159\n",
      "groundTruthY.shape[1] : 3\n",
      "   Hamming Loss  Exact Match Ratio\n",
      "0        0.0116             0.9792\n"
     ]
    }
   ],
   "source": [
    "title = \"Gaussian SVC Standardization\"\n",
    "summary[title] = multilabelEvallabelEvalilabelEvalilabelEvalltilabelEval(title, std_test_x, mfcc_test.iloc[:, -4:-1], gaussianSVC_classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8543a65",
   "metadata": {},
   "source": [
    "***1(b)-iii. Repeat 1(b)ii with L1-penalized SVMs. Remember to standardize the attributes. Determine the weight of the SVM penalty using 10 fold cross validation.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8422a8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Family (L1-penalized SVM with Standardization)\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Grid scores on development set:\n",
      "\n",
      "0.928 (+/-0.026) for {'C': 10.0}\n",
      "0.928 (+/-0.027) for {'C': 27.825594022071243}\n",
      "0.928 (+/-0.027) for {'C': 77.4263682681127}\n",
      "0.928 (+/-0.027) for {'C': 215.44346900318823}\n",
      "0.928 (+/-0.027) for {'C': 599.4842503189409}\n",
      "0.928 (+/-0.027) for {'C': 1668.100537200059}\n",
      "0.928 (+/-0.027) for {'C': 4641.588833612777}\n",
      "0.928 (+/-0.027) for {'C': 12915.496650148827}\n",
      "0.928 (+/-0.027) for {'C': 35938.13663804626}\n",
      "0.928 (+/-0.027) for {'C': 100000.0}\n",
      "\n",
      "The best parameter setting is:\n",
      "{'C': 10.0} \n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Bufonidae       0.00      0.00      0.00        15\n",
      "  Dendrobatidae       0.88      0.92      0.90       154\n",
      "        Hylidae       0.94      0.90      0.92       673\n",
      "Leptodactylidae       0.95      0.98      0.96      1317\n",
      "\n",
      "       accuracy                           0.94      2159\n",
      "      macro avg       0.69      0.70      0.70      2159\n",
      "   weighted avg       0.94      0.94      0.94      2159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L1_svm_classifiers = {}\n",
    "tuned_params = {'C' : np.logspace(1, 5, 10)}\n",
    "kwargs = {'param_grid' : tuned_params, 'cv' : splitter, 'scoring' : 'f1_weighted', 'verbose' : 1}\n",
    "\n",
    "print(f\"Class: Family (L1-penalized SVM with Standardization)\")\n",
    "L1_svm_classifiers['Family'] = paramGridSearch(LinearSVC(penalty='l1', dual=False), \n",
    "                                               kwargs, std_train_x, train_family, std_test_x, test_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1860eb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Genus (L1-penalized SVM with Standardization)\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Grid scores on development set:\n",
      "\n",
      "0.948 (+/-0.012) for {'C': 10.0}\n",
      "0.948 (+/-0.013) for {'C': 27.825594022071243}\n",
      "0.948 (+/-0.013) for {'C': 77.4263682681127}\n",
      "0.947 (+/-0.012) for {'C': 215.44346900318823}\n",
      "0.947 (+/-0.012) for {'C': 599.4842503189409}\n",
      "0.947 (+/-0.012) for {'C': 1668.100537200059}\n",
      "0.947 (+/-0.012) for {'C': 4641.588833612777}\n",
      "0.947 (+/-0.012) for {'C': 12915.496650148827}\n",
      "0.947 (+/-0.012) for {'C': 35938.13663804626}\n",
      "0.947 (+/-0.012) for {'C': 100000.0}\n",
      "\n",
      "The best parameter setting is:\n",
      "{'C': 10.0} \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Adenomera       0.96      0.99      0.98      1240\n",
      "     Ameerega       0.92      0.95      0.94       154\n",
      "Dendropsophus       0.92      0.67      0.78        91\n",
      "    Hypsiboas       0.92      0.98      0.95       479\n",
      "Leptodactylus       0.97      0.90      0.93        77\n",
      "Osteocephalus       1.00      0.36      0.53        47\n",
      "     Rhinella       0.91      0.67      0.77        15\n",
      "       Scinax       0.95      0.93      0.94        56\n",
      "\n",
      "     accuracy                           0.95      2159\n",
      "    macro avg       0.95      0.81      0.85      2159\n",
      " weighted avg       0.95      0.95      0.95      2159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Class: Genus (L1-penalized SVM with Standardization)\")\n",
    "L1_svm_classifiers['Genus'] = paramGridSearch(LinearSVC(penalty='l1', dual=False), \n",
    "                                              kwargs,std_train_x, train_genus, std_test_x, test_genus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc80c8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Species (L1-penalized SVM with Standardization)\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Grid scores on development set:\n",
      "\n",
      "0.958 (+/-0.021) for {'C': 10.0}\n",
      "0.959 (+/-0.021) for {'C': 27.825594022071243}\n",
      "0.959 (+/-0.021) for {'C': 77.4263682681127}\n",
      "0.959 (+/-0.022) for {'C': 215.44346900318823}\n",
      "0.959 (+/-0.022) for {'C': 599.4842503189409}\n",
      "0.959 (+/-0.022) for {'C': 1668.100537200059}\n",
      "0.959 (+/-0.022) for {'C': 4641.588833612777}\n",
      "0.959 (+/-0.022) for {'C': 12915.496650148827}\n",
      "0.959 (+/-0.022) for {'C': 35938.13663804626}\n",
      "0.959 (+/-0.022) for {'C': 100000.0}\n",
      "\n",
      "The best parameter setting is:\n",
      "{'C': 215.44346900318823} \n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        AdenomeraAndre       0.88      0.94      0.91       182\n",
      "AdenomeraHylaedactylus       0.99      1.00      0.99      1058\n",
      "    Ameeregatrivittata       0.94      0.94      0.94       154\n",
      "            HylaMinuta       0.92      0.71      0.80        91\n",
      "  HypsiboasCinerascens       0.92      0.94      0.93       153\n",
      "     HypsiboasCordobae       0.92      0.96      0.94       326\n",
      "   LeptodactylusFuscus       0.97      0.91      0.94        77\n",
      " OsteocephalusOophagus       1.00      0.49      0.66        47\n",
      "     Rhinellagranulosa       0.72      0.87      0.79        15\n",
      "           ScinaxRuber       0.93      0.96      0.95        56\n",
      "\n",
      "              accuracy                           0.95      2159\n",
      "             macro avg       0.92      0.87      0.88      2159\n",
      "          weighted avg       0.95      0.95      0.95      2159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Class: Species (L1-penalized SVM with Standardization)\")\n",
    "L1_svm_classifiers['Species'] = paramGridSearch(LinearSVC(penalty='l1', dual=False),\n",
    "                                                kwargs, std_train_x, train_species, std_test_x, test_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bedb4229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilabel evaluation of Support Vector Classifier with L1-penalty\n",
      "groundTruthY.shape[0] : 2159\n",
      "groundTruthY.shape[1] : 3\n",
      "   Hamming Loss  Exact Match Ratio\n",
      "0         0.052             0.9143\n"
     ]
    }
   ],
   "source": [
    "title = \"Support Vector Classifier with L1-penalty\"\n",
    "summary['SVC_L1'] = multilabelEval(title, std_test_x, mfcc_test.iloc[:, -4:-1], L1_svm_classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2746fa2",
   "metadata": {},
   "source": [
    "***1(b)-iv. Repeat 1(b)iii by using SMOTE or any other method you know to remedy class imbalance. Report your conclusions about the classifiers you trained.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f903395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Family (L1-penalized and SMOTE with Standardization)\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Grid scores on development set:\n",
      "\n",
      "0.921 (+/-0.026) for {'classification__C': 10.0}\n",
      "0.921 (+/-0.025) for {'classification__C': 27.825594022071243}\n",
      "0.921 (+/-0.023) for {'classification__C': 77.4263682681127}\n",
      "0.921 (+/-0.027) for {'classification__C': 215.44346900318823}\n",
      "0.921 (+/-0.026) for {'classification__C': 599.4842503189409}\n",
      "0.921 (+/-0.026) for {'classification__C': 1668.100537200059}\n",
      "0.921 (+/-0.027) for {'classification__C': 4641.588833612777}\n",
      "0.92 (+/-0.025) for {'classification__C': 12915.496650148827}\n",
      "0.921 (+/-0.024) for {'classification__C': 35938.13663804626}\n",
      "0.921 (+/-0.025) for {'classification__C': 100000.0}\n",
      "\n",
      "The best parameter setting is:\n",
      "{'classification__C': 215.44346900318823} \n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Bufonidae       0.24      1.00      0.38        15\n",
      "  Dendrobatidae       0.79      0.98      0.88       154\n",
      "        Hylidae       0.95      0.86      0.91       673\n",
      "Leptodactylidae       0.96      0.95      0.96      1317\n",
      "\n",
      "       accuracy                           0.92      2159\n",
      "      macro avg       0.74      0.95      0.78      2159\n",
      "   weighted avg       0.94      0.92      0.93      2159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def SMOTE_Method(classifier, settings, trainX, trainY, testX, testY):\n",
    "    naive_model = Pipeline([('sampling', SMOTE()), ('classification', classifier)])\n",
    "    selected_model = paramGridSearch(naive_model, settings, trainX, trainY, testX, testY)\n",
    "    return selected_model\n",
    "\n",
    "tuned_params = {'classification__C' : np.logspace(1, 5, 10)}\n",
    "smote_svc_classifiers = {}\n",
    "kwargs = {'param_grid' : tuned_params, 'cv' : splitter, 'scoring' : 'f1_weighted', 'verbose' : 1}\n",
    "\n",
    "print(f\"Class: Family (L1-penalized and SMOTE with Standardization)\")\n",
    "smote_svc_classifiers['Family'] = SMOTE_Method(LinearSVC(penalty='l1', dual=False), \n",
    "                                               kwargs, std_train_x, train_family, std_test_x, test_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7794a333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Genus (L1-penalized and SMOTE with Standardization)\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Grid scores on development set:\n",
      "\n",
      "0.918 (+/-0.025) for {'classification__C': 10.0}\n",
      "0.919 (+/-0.025) for {'classification__C': 27.825594022071243}\n",
      "0.919 (+/-0.023) for {'classification__C': 77.4263682681127}\n",
      "0.919 (+/-0.023) for {'classification__C': 215.44346900318823}\n",
      "0.918 (+/-0.021) for {'classification__C': 599.4842503189409}\n",
      "0.919 (+/-0.025) for {'classification__C': 1668.100537200059}\n",
      "0.918 (+/-0.023) for {'classification__C': 4641.588833612777}\n",
      "0.919 (+/-0.024) for {'classification__C': 12915.496650148827}\n",
      "0.917 (+/-0.026) for {'classification__C': 35938.13663804626}\n",
      "0.918 (+/-0.022) for {'classification__C': 100000.0}\n",
      "\n",
      "The best parameter setting is:\n",
      "{'classification__C': 12915.496650148827} \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Adenomera       0.99      0.91      0.95      1240\n",
      "     Ameerega       0.83      0.92      0.87       154\n",
      "Dendropsophus       0.64      0.97      0.77        91\n",
      "    Hypsiboas       0.98      0.90      0.94       479\n",
      "Leptodactylus       0.92      0.90      0.91        77\n",
      "Osteocephalus       0.61      0.77      0.68        47\n",
      "     Rhinella       0.22      0.93      0.36        15\n",
      "       Scinax       0.86      0.96      0.91        56\n",
      "\n",
      "     accuracy                           0.91      2159\n",
      "    macro avg       0.75      0.91      0.80      2159\n",
      " weighted avg       0.94      0.91      0.92      2159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Class: Genus (L1-penalized and SMOTE with Standardization)\")\n",
    "smote_svc_classifiers['Genus'] = SMOTE_Method(LinearSVC(penalty='l1', dual=False), \n",
    "                                              kwargs, std_train_x, train_genus, std_test_x, test_genus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb7685ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Species (L1-penalized and SMOTE with Standardization)\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Grid scores on development set:\n",
      "\n",
      "0.957 (+/-0.015) for {'classification__C': 10.0}\n",
      "0.957 (+/-0.017) for {'classification__C': 27.825594022071243}\n",
      "0.957 (+/-0.017) for {'classification__C': 77.4263682681127}\n",
      "0.956 (+/-0.017) for {'classification__C': 215.44346900318823}\n",
      "0.956 (+/-0.019) for {'classification__C': 599.4842503189409}\n",
      "0.958 (+/-0.017) for {'classification__C': 1668.100537200059}\n",
      "0.956 (+/-0.017) for {'classification__C': 4641.588833612777}\n",
      "0.956 (+/-0.019) for {'classification__C': 12915.496650148827}\n",
      "0.958 (+/-0.018) for {'classification__C': 35938.13663804626}\n",
      "0.956 (+/-0.015) for {'classification__C': 100000.0}\n",
      "\n",
      "The best parameter setting is:\n",
      "{'classification__C': 35938.13663804626} \n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        AdenomeraAndre       0.96      0.93      0.94       182\n",
      "AdenomeraHylaedactylus       0.99      1.00      0.99      1058\n",
      "    Ameeregatrivittata       0.94      0.88      0.91       154\n",
      "            HylaMinuta       0.83      0.90      0.86        91\n",
      "  HypsiboasCinerascens       0.93      0.92      0.93       153\n",
      "     HypsiboasCordobae       0.95      0.91      0.93       326\n",
      "   LeptodactylusFuscus       0.92      0.90      0.91        77\n",
      " OsteocephalusOophagus       0.79      0.70      0.74        47\n",
      "     Rhinellagranulosa       0.37      0.93      0.53        15\n",
      "           ScinaxRuber       0.90      0.96      0.93        56\n",
      "\n",
      "              accuracy                           0.95      2159\n",
      "             macro avg       0.86      0.90      0.87      2159\n",
      "          weighted avg       0.95      0.95      0.95      2159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Class: Species (L1-penalized and SMOTE with Standardization)\")\n",
    "smote_svc_classifiers['Species'] = SMOTE_Method(LinearSVC(penalty='l1', dual=False),\n",
    "                                                kwargs, std_train_x, train_species, std_test_x, test_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e728b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilabel evaluation of SVM with L1 penalty and SMOTE\n",
      "groundTruthY.shape[0] : 2159\n",
      "groundTruthY.shape[1] : 3\n",
      "   Hamming Loss  Exact Match Ratio\n",
      "0        0.0718              0.856\n"
     ]
    }
   ],
   "source": [
    "title = 'SVM with L1 penalty and SMOTE'\n",
    "summary['SVC_L1_SMOTE'] = multilabelEval(title, std_test_x, mfcc_test.iloc[:, -4:-1], smote_svc_classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c6f2f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gaussian SVC without Standardization</th>\n",
       "      <th>Gaussian SVC Standardization</th>\n",
       "      <th>SVC_L1</th>\n",
       "      <th>SVC_L1_SMOTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>0.0718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9852</td>\n",
       "      <td>0.9792</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>0.8560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gaussian SVC without Standardization  Gaussian SVC Standardization  SVC_L1  \\\n",
       "0                                0.0096                        0.0116  0.0520   \n",
       "1                                0.9852                        0.9792  0.9143   \n",
       "\n",
       "   SVC_L1_SMOTE  \n",
       "0        0.0718  \n",
       "1        0.8560  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarized_SVCs = pd.DataFrame(data=summary)\n",
    "summarized_SVCs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d20afb1",
   "metadata": {},
   "source": [
    "## 2. K-Means Clustering on a Multi-Class and Multi-Label Data Set | Monte Carlo Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de441500",
   "metadata": {},
   "source": [
    "**Monte-Carlo Simulation: Perform the following procedures 50 times, and report the average and standard deviation of the 50 Hamming Distances that you calculate.**\n",
    "\n",
    "**2(a). Use k-means clustering on the whole Anuran Calls (MFCCs) Data Set (do not split the data into train and test, as we are not performing supervised learning in this exercise). Choose $k ∈ {1,2, . . . ,50}$ automatically based on one of the methods provided in the slides (CH or Gap Statistics or scree plots or Silhouettes) or any other method you know.**\n",
    "\n",
    "**2(b). In each cluster, determine which family is the majority by reading the true labels. Repeat for genus and species.**\n",
    "\n",
    "**2(c). Now for each cluster you have a majority label triplet (family, genus, species). Calculate the average Hamming distance, Hamming score, and Hamming loss between the true labels and the labels assigned by clusters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d46cc11f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal K is: 4\n",
      "Iteration 1 | Hamming Distance: 0.6653, Hamming Loss: 0.2218\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 2 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 3 | Hamming Distance: 0.7358, Hamming Loss: 0.2453\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 4 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 5 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 6 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 7 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 8 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 9 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 10 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 11 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 12 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 13 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 14 | Hamming Distance: 0.6674, Hamming Loss: 0.2225\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 15 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 16 | Hamming Distance: 0.6674, Hamming Loss: 0.2225\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 17 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 18 | Hamming Distance: 0.7012, Hamming Loss: 0.2337\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 19 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 20 | Hamming Distance: 0.6653, Hamming Loss: 0.2218\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 21 | Hamming Distance: 0.7022, Hamming Loss: 0.2341\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 22 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 23 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 24 | Hamming Distance: 0.6674, Hamming Loss: 0.2225\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 25 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 26 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 27 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 28 | Hamming Distance: 0.6674, Hamming Loss: 0.2225\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 29 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 30 | Hamming Distance: 0.6664, Hamming Loss: 0.2221\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 31 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 32 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 33 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 34 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 35 | Hamming Distance: 0.5582, Hamming Loss: 0.1861\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 36 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 37 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 38 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 39 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 40 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 41 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 42 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 43 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 44 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 45 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 46 | Hamming Distance: 0.6653, Hamming Loss: 0.2218\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 47 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 48 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 49 | Hamming Distance: 0.8402, Hamming Loss: 0.2801\n",
      "\n",
      "The optimal K is: 4\n",
      "Iteration 50 | Hamming Distance: 0.6673, Hamming Loss: 0.2224\n"
     ]
    }
   ],
   "source": [
    "# Below provides Optimal value of K\n",
    "def Optimal_K(num_cluster, X, rand):\n",
    "    optimalK, max_score = 2, 0\n",
    "    num_cluster = num_cluster + 1\n",
    "    for n in range(2, num_cluster):\n",
    "        clusterer = KMeans(n_clusters=n, random_state=rand)\n",
    "        cluster_labels = clusterer.fit_predict(X)\n",
    "        silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "        if silhouette_avg > max_score:\n",
    "            optimalK = n\n",
    "            max_score = silhouette_avg\n",
    "    print(f\"\\nThe optimal K is: {optimalK}\")\n",
    "    return optimalK\n",
    "\n",
    "# Gets Majority Labels of a Cluster\n",
    "def getMajorityLabels(optimalK, cluster_labels, Y):\n",
    "    cluster_major = pd.DataFrame(columns=Y.columns)\n",
    "    for c in range(optimalK):\n",
    "        idx, = np.where(cluster_labels == c)\n",
    "        cluster_samples = Y.iloc[idx, :]\n",
    "        row = []\n",
    "        for label in Y.columns:\n",
    "            cur_major = cluster_samples.loc[:, label].value_counts().index[0]\n",
    "            row.append(cur_major)\n",
    "        cluster_major.loc[c] = row\n",
    "    return cluster_major\n",
    "\n",
    "# Calculate Hamming Loss\n",
    "def evaluation(cluster_major, cluster_labels, Y):\n",
    "    missclf_labels = 0\n",
    "    for c in range(len(cluster_major)):\n",
    "        idx, = np.where(cluster_labels == c)\n",
    "        for label in Y.loc[idx].values:\n",
    "            miss = (label != cluster_major.loc[c].values)\n",
    "            missclf_labels += np.sum(miss)\n",
    "    hamming_dist = missclf_labels / Y.shape[0]\n",
    "    hamming_loss = missclf_labels / (Y.shape[0] * Y.shape[1])\n",
    "    return hamming_dist, hamming_loss\n",
    "\n",
    "def MonteCarloSimulation(times, X, Y):\n",
    "    hamming_dist = []\n",
    "    hamming_loss = []\n",
    "    for i in range(times):\n",
    "        optimalK = Optimal_K(50, X, i)\n",
    "        clusterer = KMeans(n_clusters=optimalK, random_state=i)\n",
    "        cluster_labels = clusterer.fit_predict(X)\n",
    "        cluster_major = getMajorityLabels(optimalK, cluster_labels, Y)\n",
    "        cur_dist, cur_loss = evaluation(cluster_major, cluster_labels, Y)\n",
    "        hamming_dist.append(cur_dist)\n",
    "        hamming_loss.append(cur_loss)\n",
    "        print(f\"Iteration {i + 1} | Hamming Distance: {round(cur_dist, 4)}, Hamming Loss: {round(cur_loss, 4)}\")\n",
    "    return hamming_dist, hamming_loss\n",
    "\n",
    "iterations = 50\n",
    "hamming_dist, hamming_loss = MonteCarloSimulation(iterations, mfcc_data.iloc[:, :-4], mfcc_data.iloc[:, -4:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c607e1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Hamming Distance</th>\n",
       "      <th>Std Devation (Hamming Distance)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6712</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Hamming Distance  Std Devation (Hamming Distance)\n",
       "0                    0.6712                            0.031"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summary(hamming_distance, hamming_loss):\n",
    "    summary_hd = {\n",
    "        \"Average Hamming Distance\": [round(np.mean(hamming_distance), 4)],\n",
    "        \"Std Devation (Hamming Distance)\": [round(np.std(hamming_distance), 4)]\n",
    "    }\n",
    "    \n",
    "    summary_hl = {\n",
    "        \"Average Hamming Loss\": [round(np.mean(hamming_loss), 4)],\n",
    "        \"Std Devation (Hamming Loss)\": [round(np.std(hamming_loss), 4)]\n",
    "    }\n",
    "    \n",
    "    summary_h_score = {\n",
    "        \"Average Hamming Score\": [round(1 - np.mean(hamming_loss), 4)],\n",
    "        \"Std Devation (Hamming Score)\": [round(np.std(hamming_loss), 4)]\n",
    "    }\n",
    "    \n",
    "    df_summary_hd = pd.DataFrame(data=summary_hd)\n",
    "    df_summary_hl = pd.DataFrame(data=summary_hl)\n",
    "    df_summary_h_score = pd.DataFrame(data=summary_h_score)\n",
    "    \n",
    "    return [df_summary_hd, df_summary_hl, df_summary_h_score]\n",
    "\n",
    "hamming_distance_summary, hamming_loss_summary, hamming_score_summary = summary(hamming_dist, hamming_loss)\n",
    "hamming_distance_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8246fec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Hamming Loss</th>\n",
       "      <th>Std Devation (Hamming Loss)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2237</td>\n",
       "      <td>0.0103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Hamming Loss  Std Devation (Hamming Loss)\n",
       "0                0.2237                       0.0103"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_loss_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d27c9ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Hamming Score</th>\n",
       "      <th>Std Devation (Hamming Score)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7763</td>\n",
       "      <td>0.0103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Hamming Score  Std Devation (Hamming Score)\n",
       "0                 0.7763                        0.0103"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_score_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc537d30",
   "metadata": {},
   "source": [
    "### 3. ISLR 12.6.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007e01c8",
   "metadata": {},
   "source": [
    "Suppose that we have four observations, for which we compute a dissimilarity matrix, given by\n",
    "\n",
    "\\begin{bmatrix}\n",
    "&  0.3 & 0.4 & 0.7\\\\\n",
    "0.3 & &       0.5 & 0.8\\\\\n",
    "0.4 & 0.5       & & 0.45\\\\\n",
    "0.7 & 0.8 & 0.45 &\n",
    "\\end{bmatrix}\n",
    "\n",
    "For instance, the dissimilarity between the first and second observations is 0.3, and the dissimilarity between the second and fourth observations is 0.8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79687f4",
   "metadata": {},
   "source": [
    "**(a). On the basis of this dissimilarity matrix, sketch the dendrogram that results from hierarchically clustering these four observations using complete linkage. Be sure to indicate on the plot the height at which each fusion occurs, as well as the observations corresponding to each leaf in the dendrogram.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "75c29637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHGCAYAAACIDqqPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABGWElEQVR4nO3deVhV5d7/8c+WWVEcUJwQHHKe8eSUaZYYTmWDHs2pJDMsc6on8phDA2VpeDqhmVOWGVnaKSOVnNLUniRsUNNMDTQQxRQrY7x/f/hjP24BRUT3dvl+Xde+Lta97nWv71prIx/XsLfNGGMEAABgEWWcXQAAAEBpItwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdzAJS1ZskQ2m83+8vb2VvXq1XXbbbcpKipKaWlpTq0vODhYI0aMcGoNrur1119XgwYN5OnpKZvNplOnTl31dX7//fd68MEHVbduXXl7e8vX11dt27bVzJkzdfLkyau+/ivRrVs3devWrUTLxsTEaMmSJaVajySNGDFCvr6+F+2T/zt6+PDhyx5/06ZNstls+vDDD0tYIXBx7s4uALiYxYsXq3HjxsrOzlZaWpq2bt2ql19+Wa+++qpiY2N1xx13OLtEnGfXrl0aO3aswsPDNXz4cLm7u6t8+fJXdZ1vvfWWIiIi1KhRIz355JNq2rSpsrOztXPnTs2bN0/bt2/XqlWrrmoNzhITEyN/f3+nBO3evXtr+/btqlGjxjVfN3AphBu4tObNm6tdu3b26XvvvVfjx4/XLbfconvuuUc///yzAgICnFhh0c6ePStvb2/ZbLarvq7s7GzZbDa5uzv3V3r37t2SpIcfflg333xzqYz5119/qWzZsoXO2759ux599FH16NFDH3/8sby8vOzzevTooYkTJ2rNmjWlUgccVa1aVVWrVnV2GUChuCyF606dOnU0a9YsnTlzRm+++abDvJ07d6pfv36qXLmyvL291aZNG33wwQcOffJPp2/cuFGPPvqo/P39VaVKFd1zzz367bffHPpmZ2frqaeeUvXq1VW2bFndcsst+t///d8CNeWPuW7dOj300EOqWrWqypYtq8zMTOXl5WnmzJlq3LixvLy8VK1aNQ0bNkxHjhxxGMMYoxdffFFBQUHy9vZWu3btFB8fX+CyRf4p/XfeeUcTJ05UrVq15OXlpQMHDuj48eOKiIhQ06ZN5evrq2rVqql79+7asmWLw7oOHz4sm82mV155RS+//LKCg4Pl4+Ojbt26af/+/crOztbTTz+tmjVrys/PT/3797/kpcBu3bppyJAhkqT27dvLZrM5nFFYtGiRWrVqJW9vb1WuXFn9+/fX3r17HcbIvxzyww8/KDQ0VOXLl9ftt99e5DpffPFF2Ww2zZ8/3yHY5PP09FS/fv3s08U9Ft26dVPz5s21fft2derUST4+PgoODtbixYslSZ999pnatm2rsmXLqkWLFgUC1LRp02Sz2ZSYmKh77rlHFSpUkJ+fn4YMGaLjx49fdD9KUlZWlp5//nl7nVWrVtWDDz7osGxwcLB2796tzZs32y/fBgcH2+dnZGRo0qRJqlu3rjw9PVWrVi2NGzdOf/755yXXXxyFXZbK32/ffPONunTporJly6pevXp66aWXlJeXd9HxMjIy1LNnTwUEBNh/x+Lj43XXXXepdu3a8vb2VoMGDfTII4/oxIkTBZb/73//q5YtW8rLy0v16tXTnDlz7MfhfMYYxcTEqHXr1vLx8VGlSpV033336eDBg1e+U+A6DOCCFi9ebCSZb775ptD5f/zxh3FzczO33367vW3Dhg3G09PTdOnSxcTGxpo1a9aYESNGGElm8eLFBcauV6+eefzxx83atWvNggULTKVKlcxtt93msJ7hw4cbm81mnnzySbNu3Toze/ZsU6tWLVOhQgUzfPjwAmPWqlXLjBo1ynz++efmww8/NDk5OWbUqFFGknnsscfMmjVrzLx580zVqlVNYGCgOX78uH2MyMhII8mMGjXKrFmzxrz11lumTp06pkaNGqZr1672fhs3brSv67777jOffPKJWb16tUlPTzc//fSTefTRR837779vNm3aZFavXm1GjhxpypQpYzZu3Ggf49ChQ0aSCQoKMn379jWrV6827777rgkICDANGzY0Q4cONQ899JD5/PPPzbx584yvr6/p27fvRY/Z7t27zb/+9S/7/t6+fbs5cOCAMcaYF1980UgygwYNMp999plZunSpqVevnvHz8zP79+932N8eHh4mODjYREVFmfXr15u1a9cWur6cnBxTtmxZ0759+4vWdb7iHouuXbuaKlWqmEaNGpmFCxeatWvXmj59+hhJZvr06aZFixZm+fLlJi4uznTo0MF4eXmZo0eP2pefOnWqff8++eSTZu3atWb27NmmXLlypk2bNiYrK8thXecf39zcXHPnnXeacuXKmenTp5v4+HizYMECU6tWLdO0aVPz119/GWOM+fbbb029evVMmzZtzPbt28327dvNt99+a4wx5s8//zStW7c2/v7+Zvbs2eaLL74wc+bMMX5+fqZ79+4mLy/vovtp+PDhply5chftk/+eP3ToUIH9dtNNN5l58+aZ+Ph4ExERYSSZt99+294v/z28YsUKY4wxycnJpkWLFqZRo0bml19+sfebO3euiYqKMp988onZvHmzefvtt02rVq1Mo0aNHPbh559/bsqUKWO6detmVq1aZVasWGHat29vgoODzYV/5h5++GHj4eFhJk6caNasWWPee+8907hxYxMQEGBSU1Mvus24fhBu4JIuFW6MMSYgIMA0adLEPt24cWPTpk0bk52d7dCvT58+pkaNGiY3N9dh7IiICId+M2fONJJMSkqKMcaYvXv3Gklm/PjxDv2WLVtmJBUaboYNG+bQN3+MC9f19ddfG0nmmWeeMcYYc/LkSePl5WUGDhzo0G/79u1GUqHh5tZbby1y3+TLyckx2dnZ5vbbbzf9+/e3t+eHm1atWtn3izHGREdHG0mmX79+DuOMGzfOSDKnT5++6PoKO26///678fHxMb169XLom5SUZLy8vMzgwYPtbcOHDzeSzKJFiy65bampqUaS+ec//3nJvsYU/1gYc+6PtCSzc+dOe1t6erpxc3MzPj4+DkFm165dRpL597//bW/LDzdFvXfeffddh3Wdf3yXL19uJJmPPvrIYdlvvvnGSDIxMTH2tmbNmjksmy8qKsqUKVOmwO/Phx9+aCSZuLi4wnaR3ZWEG0nm66+/dujbtGlT07NnT/v0+eEmMTHR1KxZ03Tp0sWkp6cXub68vDyTnZ1tfv31VyPJ/Pe//7XP+8c//mECAwNNZmamve3MmTOmSpUqDuEm//dp1qxZDmMnJycbHx8f89RTT110m3H94LIUrlvGGPvPBw4c0E8//aQHHnhAkpSTk2N/9erVSykpKdq3b5/D8udfrpCkli1bSpJ+/fVXSdLGjRslyT5mvgEDBhR5b8u9997rMJ0/xoU3fN58881q0qSJ1q9fL0nasWOHMjMzNWDAAId+HTp0cLjUcLF15Zs3b57atm0rb29vubu7y8PDQ+vXry9wCUiSevXqpTJl/u+fgSZNmkg6d7Po+fLbk5KSCl3nxWzfvl1nz54tsA8CAwPVvXt3+z44X1HbdiWKeyzy1ahRQyEhIfbpypUrq1q1amrdurVq1qxpb8/fN/nvm/MV9d7Jr6Uwq1evVsWKFdW3b1+H93Hr1q1VvXp1bdq06ZLbunr1ajVv3lytW7d2GKNnz56y2WzFGqOkqlevXuB+q5YtWxa6f9auXasuXbro1ltvVXx8vCpXruwwPy0tTaNHj1ZgYKD9vRwUFCRJ9vfzn3/+qZ07d+ruu++Wp6enfVlfX1/17dvXYbzVq1fLZrNpyJAhDvulevXqatWq1VXdL7i2uKEY16U///xT6enpatGihSTp2LFjkqRJkyZp0qRJhS5z4XX6KlWqOEzn37Nx9uxZSVJ6erqkc/9Yn8/d3b3AsvkufHIkf4zCniipWbOm/R/8/H6F3Rxd1A3ThY05e/ZsTZw4UaNHj9Zzzz0nf39/ubm5acqUKYWGmwv/mOT/cSiq/e+//y60lou51D6Ij493aCtbtqwqVKhwyXH9/f1VtmxZHTp0qFTquPCP74X7QDq3Hy5n3xT13smvpTDHjh3TqVOnHP5Qn6+w+00KG+PAgQPy8PAo8RglVdjvhpeXl/336nwff/yxzp49q0cffbTAPVN5eXkKDQ3Vb7/9pilTpqhFixYqV66c8vLy1KFDB/t4v//+u4wxxfrdOXbsWJF9JalevXrF3k64NsINrkufffaZcnNz7Tfa+vv7S5IiIyN1zz33FLpMo0aNLmsd+f9Ip6amqlatWvb2nJycIv84XXjzYv4YKSkpql27tsO83377zV53fr/8kHa+1NTUQs/eFPYU1rvvvqtu3bpp7ty5Du1nzpwptN5r4fx9cKHz90G+4j5d5ubmpttvv12ff/65jhw5UmD/XqyOix2L0lTUe6eocCzJfoN7UU95FefRen9/f/n4+GjRokVFzncFr732mmJjYxUWFqZVq1YpNDTUPu/HH3/Ud999pyVLlmj48OH29gMHDjiMUalSJdlstiJ/d87n7+8vm82mLVu2FHoDemFtuD5xWQrXnaSkJE2aNEl+fn565JFHJJ0LLjfddJO+++47tWvXrtDX5X7eSn5wWrZsmUP7Bx98oJycnGKN0b17d0nnQsf5vvnmG+3du9f+JFD79u3l5eWl2NhYh347duwo9HR+UWw2W4F/oL///ntt37692GOUto4dO8rHx6fAPjhy5Ig2bNhw0aehLiUyMlLGGD388MPKysoqMD87O1uffvqppOIfi9JU1HvnYh/a16dPH6Wnpys3N7fQ9/H5Ib2oMyJ9+vTRL7/8oipVqhQ6RlGXOq81b29vrVy5Un369FG/fv303//+1z4vP+Re+H6+8AnJcuXKqV27dvr4448d3gN//PGHVq9e7dC3T58+Msbo6NGjhe6X/DPBuP5x5gYu7ccff7RfF09LS9OWLVu0ePFiubm5adWqVQ6fs/Hmm28qLCxMPXv21IgRI1SrVi2dPHlSe/fu1bfffqsVK1Zc1rqbNGmiIUOGKDo6Wh4eHrrjjjv0448/6tVXXy3WZRPpXOgaNWqUXn/9dZUpU0ZhYWE6fPiwpkyZosDAQI0fP17SuUsgEyZMUFRUlCpVqqT+/fvryJEjmj59umrUqOFwX8zF9OnTR88995ymTp2qrl27at++fZoxY4bq1q1b7EBW2ipWrKgpU6bomWee0bBhwzRo0CClp6dr+vTp8vb21tSpU0s8dseOHTV37lxFREQoJCREjz76qJo1a6bs7GwlJiZq/vz5at68ufr27VvsY1GaVq5cKXd3d/Xo0UO7d+/WlClT1KpVqwL3Vp3vn//8p5YtW6ZevXrpiSee0M033ywPDw8dOXJEGzdu1F133aX+/ftLklq0aKH3339fsbGxqlevnry9vdWiRQuNGzdOH330kW699VaNHz9eLVu2VF5enpKSkrRu3TpNnDhR7du3v2jtubm5hX6CcLly5RQWFnZlO+Y8Hh4eWr58ucLDw3Xfffdp6dKlGjRokBo3bqz69evr6aefljFGlStX1qefflrgMqYkzZgxQ71791bPnj31xBNPKDc3V6+88op8fX0dPqG6c+fOGjVqlB588EHt3LlTt956q8qVK6eUlBRt3bpVLVq00KOPPlpq2wYncubdzEBR8p/EyH95enqaatWqma5du5oXX3zRpKWlFbrcd999ZwYMGGCqVatmPDw8TPXq1U337t3NvHnzCox94ZMk+U9wnP/IdGZmppk4caKpVq2a8fb2Nh06dDDbt283QUFBhT4tVdjTXbm5uebll182DRs2NB4eHsbf398MGTLEJCcnO/TLy8szzz//vKldu7bx9PQ0LVu2NKtXrzatWrVyeNLpwsdoz5eZmWkmTZpkatWqZby9vU3btm3Nxx9/bIYPH26CgoLs/fKflnrllVcK3QcXjl2cp9cu1W/BggWmZcuWxtPT0/j5+Zm77rrL7N6926FPcZ7SKcyuXbvM8OHDTZ06dYynp6f9ketnn33W4b1S3GPRtWtX06xZswLrCQoKMr179y7QLsmMGTPGPp3/tFRCQoLp27ev8fX1NeXLlzeDBg0yx44dK7CuC594ys7ONq+++qpp1aqV8fb2Nr6+vqZx48bmkUceMT///LO93+HDh01oaKgpX768/dHzfH/88Yf517/+ZRo1amTf5y1atDDjx4+/5CPP+U+tFfbKX0dRT0sVtt8ufP8V9j7Ly8szY8eONWXKlDFvvfWWMcaYPXv2mB49epjy5cubSpUqmfvvv98kJSUZSWbq1KkO61i1apVp0aKF8fT0NHXq1DEvvfSSGTt2rKlUqVKBehYtWmTat29vypUrZ3x8fEz9+vXNsGHDHJ6Ow/XNZsx5j5wAcCmHDh1S48aNNXXqVD3zzDPOLgfFNG3aNE2fPl3Hjx93mftbbjTZ2dlq3bq1atWqpXXr1jm7HFxjXJYCXMR3332n5cuXq1OnTqpQoYL27dunmTNnqkKFCho5cqSzywNc2siRI9WjRw/VqFFDqampmjdvnvbu3as5c+Y4uzQ4AeEGcBHlypXTzp07tXDhQp06dUp+fn7q1q2bXnjhBZf9/izAVZw5c0aTJk3S8ePH5eHhobZt2youLo4v171BcVkKAABYCo+CAwAASyHcAAAASyHcAAAAS7nhbijOy8vTb7/9pvLlyxf7Y94BAIBzGWN05swZ1axZ85IfbHrDhZvffvtNgYGBzi4DAACUQHJy8iW/S+6GCzf53y+UnJxc7I/QBwAAzpWRkaHAwMBifU/gDRdu8i9FVahQgXADAMB1pji3lHBDMQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBSnh5uYmBjVrVtX3t7eCgkJ0ZYtWy7af9myZWrVqpXKli2rGjVq6MEHH1R6evo1qhYAALg6p4ab2NhYjRs3TpMnT1ZiYqK6dOmisLAwJSUlFdp/69atGjZsmEaOHKndu3drxYoV+uabbxQeHn6NKwcAAK7KqeFm9uzZGjlypMLDw9WkSRNFR0crMDBQc+fOLbT/jh07FBwcrLFjx6pu3bq65ZZb9Mgjj2jnzp3XuHIAAOCqnPat4FlZWUpISNDTTz/t0B4aGqpt27YVukynTp00efJkxcXFKSwsTGlpafrwww/Vu3fva1EyrkPGGJ3NznV2GQCuEh8Pt2J9SzRuLE4LNydOnFBubq4CAgIc2gMCApSamlroMp06ddKyZcs0cOBA/f3338rJyVG/fv30+uuvF7mezMxMZWZm2qczMjJKZwPg8owxum/ediX8+ruzSwFwlbQLqqQVozsScODA6TcUX/iGNMYU+Sbds2ePxo4dq2effVYJCQlas2aNDh06pNGjRxc5flRUlPz8/OyvwMDAUq0frutsdi7BBrC4nb/+ztlZFOC0Mzf+/v5yc3MrcJYmLS2twNmcfFFRUercubOefPJJSVLLli1Vrlw5denSRc8//7xq1KhRYJnIyEhNmDDBPp2RkUHAuQHt/NcdKuvp5uwyAJSSv7Jy1e75L5xdBlyU08KNp6enQkJCFB8fr/79+9vb4+PjdddddxW6zF9//SV3d8eS3dzO/cEyxhS6jJeXl7y8vEqpalyvynq6qayn097uAIBryKmXpSZMmKAFCxZo0aJF2rt3r8aPH6+kpCT7ZabIyEgNGzbM3r9v375auXKl5s6dq4MHD+qrr77S2LFjdfPNN6tmzZrO2gwAAOBCnPpf2YEDByo9PV0zZsxQSkqKmjdvrri4OAUFBUmSUlJSHD7zZsSIETpz5oz+85//aOLEiapYsaK6d++ul19+2VmbAAAAXIzNFHU9x6IyMjLk5+en06dPq0KFCs4uB1fRX1k5avrsWknSnhk9uSwFWAi/3zeey/n77fSnpQAAAEoT4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFiK08NNTEyM6tatK29vb4WEhGjLli1F9h0xYoRsNluBV7Nmza5hxQAAwJU5NdzExsZq3Lhxmjx5shITE9WlSxeFhYUpKSmp0P5z5sxRSkqK/ZWcnKzKlSvr/vvvv8aVAwAAV+XUcDN79myNHDlS4eHhatKkiaKjoxUYGKi5c+cW2t/Pz0/Vq1e3v3bu3Knff/9dDz744DWuHAAAuCqnhZusrCwlJCQoNDTUoT00NFTbtm0r1hgLFy7UHXfcoaCgoKtRIgAAuA65O2vFJ06cUG5urgICAhzaAwIClJqaesnlU1JS9Pnnn+u99967aL/MzExlZmbapzMyMkpWMAAAuC44/YZim83mMG2MKdBWmCVLlqhixYq6++67L9ovKipKfn5+9ldgYOCVlAsAAFyc08KNv7+/3NzcCpylSUtLK3A250LGGC1atEhDhw6Vp6fnRftGRkbq9OnT9ldycvIV1w4AAFyX08KNp6enQkJCFB8f79AeHx+vTp06XXTZzZs368CBAxo5cuQl1+Pl5aUKFSo4vAAAgHU57Z4bSZowYYKGDh2qdu3aqWPHjpo/f76SkpI0evRoSefOuhw9elRLly51WG7hwoVq3769mjdv7oyyAQCAC3NquBk4cKDS09M1Y8YMpaSkqHnz5oqLi7M//ZSSklLgM29Onz6tjz76SHPmzHFGyQAAwMU5NdxIUkREhCIiIgqdt2TJkgJtfn5++uuvv65yVQAA4Hrl9KelAAAAShPhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWIrTw01MTIzq1q0rb29vhYSEaMuWLRftn5mZqcmTJysoKEheXl6qX7++Fi1adI2qBQAArs7dmSuPjY3VuHHjFBMTo86dO+vNN99UWFiY9uzZozp16hS6zIABA3Ts2DEtXLhQDRo0UFpamnJycq5x5QAAwFU5NdzMnj1bI0eOVHh4uCQpOjpaa9eu1dy5cxUVFVWg/5o1a7R582YdPHhQlStXliQFBwdfy5IBAICLc9plqaysLCUkJCg0NNShPTQ0VNu2bSt0mU8++UTt2rXTzJkzVatWLTVs2FCTJk3S2bNnr0XJAADgOuC0MzcnTpxQbm6uAgICHNoDAgKUmppa6DIHDx7U1q1b5e3trVWrVunEiROKiIjQyZMni7zvJjMzU5mZmfbpjIyM0tsIAADgcpx+Q7HNZnOYNsYUaMuXl5cnm82mZcuW6eabb1avXr00e/ZsLVmypMizN1FRUfLz87O/AgMDS30bAACA63BauPH395ebm1uBszRpaWkFzubkq1GjhmrVqiU/Pz97W5MmTWSM0ZEjRwpdJjIyUqdPn7a/kpOTS28jAACAy3FauPH09FRISIji4+Md2uPj49WpU6dCl+ncubN+++03/fHHH/a2/fv3q0yZMqpdu3ahy3h5ealChQoOLwAAYF1OvSw1YcIELViwQIsWLdLevXs1fvx4JSUlafTo0ZLOnXUZNmyYvf/gwYNVpUoVPfjgg9qzZ4++/PJLPfnkk3rooYfk4+PjrM0AAAAuxKmPgg8cOFDp6emaMWOGUlJS1Lx5c8XFxSkoKEiSlJKSoqSkJHt/X19fxcfH6/HHH1e7du1UpUoVDRgwQM8//7yzNgEAALgYp4YbSYqIiFBERESh85YsWVKgrXHjxgUuZQEAAORz+tNSAAAApYlwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALMXp4SYmJkZ169aVt7e3QkJCtGXLliL7btq0STabrcDrp59+uoYVAwAAV+bUcBMbG6tx48Zp8uTJSkxMVJcuXRQWFqakpKSLLrdv3z6lpKTYXzfddNM1qhgAALg6p4ab2bNna+TIkQoPD1eTJk0UHR2twMBAzZ0796LLVatWTdWrV7e/3NzcrlHFAADA1Tkt3GRlZSkhIUGhoaEO7aGhodq2bdtFl23Tpo1q1Kih22+/XRs3bryaZQIAgOuMu7NWfOLECeXm5iogIMChPSAgQKmpqYUuU6NGDc2fP18hISHKzMzUO++8o9tvv12bNm3SrbfeWugymZmZyszMtE9nZGSU3kYAAACX47Rwk89mszlMG2MKtOVr1KiRGjVqZJ/u2LGjkpOT9eqrrxYZbqKiojR9+vTSKxgAALg0p12W8vf3l5ubW4GzNGlpaQXO5lxMhw4d9PPPPxc5PzIyUqdPn7a/kpOTS1wzAABwfU4LN56engoJCVF8fLxDe3x8vDp16lTscRITE1WjRo0i53t5ealChQoOLwAAYF1OvSw1YcIEDR06VO3atVPHjh01f/58JSUlafTo0ZLOnXU5evSoli5dKkmKjo5WcHCwmjVrpqysLL377rv66KOP9NFHHzlzMwAAgAtxargZOHCg0tPTNWPGDKWkpKh58+aKi4tTUFCQJCklJcXhM2+ysrI0adIkHT16VD4+PmrWrJk+++wz9erVy1mbAAAAXIzNGGOcXcS1lJGRIT8/P50+fZpLVBb3V1aOmj67VpK0Z0ZPlfV0+v3zAEoJv983nsv5++30r18AAAAoTYQbAABgKVccbv7+++/SqAMAAKBUlCjc5OXl6bnnnlOtWrXk6+urgwcPSpKmTJmihQsXlmqBAAAAl6NE4eb555/XkiVLNHPmTHl6etrbW7RooQULFpRacQAAAJerROFm6dKlmj9/vh544AGHb+Ru2bKlfvrpp1IrDgAA4HKVKNwcPXpUDRo0KNCel5en7OzsKy4KAACgpEoUbpo1a6YtW7YUaF+xYoXatGlzxUUBAACUVIk+9Wjq1KkaOnSojh49qry8PK1cuVL79u3T0qVLtXr16tKuEQAAoNhKdOamb9++io2NVVxcnGw2m5599lnt3btXn376qXr06FHaNQIAABRbiT+vumfPnurZs2dp1gIAAHDFSnTm5ptvvtHXX39doP3rr7/Wzp07r7goAACAkipRuBkzZoySk5MLtB89elRjxoy54qIAAABKqkThZs+ePWrbtm2B9jZt2mjPnj1XXBQAAEBJleieGy8vLx07dkz16tVzaE9JSZG7O187DwDXkjFGZ3POOruMa+qv7Nzzfj4r2dwu0tt6fNx9ZLPZnF2GyypREunRo4ciIyP13//+V35+fpKkU6dO6ZlnnuFpKQC4howxGvb5MO06vsvZpVxTJs9D0nOSpG4fdJWtzI31AbJtqrXR23e+TcApQonCzaxZs3TrrbcqKCjI/qF9u3btUkBAgN55551SLRAAULSzOWdvuGAjSbYy2Srf5Glnl+E0iWmJOptzVmU9yjq7FJdUonBTq1Ytff/991q2bJm+++47+fj46MEHH9SgQYPk4eFR2jUCAIph04BN8nH3cXYZuIrO5pxVtw+6ObsMl1fiG2TKlSunUaNGlWYtAIAr4OPuw//kAV1BuNm/f782bdqktLQ05eXlOcx79tlnr7gwAACAkihRuHnrrbf06KOPyt/fX9WrV3e4oSn/6xgAAACcoUTh5vnnn9cLL7yg//mf/yntegAAAK5IiT7E7/fff9f9999f2rUAAABcsRKFm/vvv1/r1q0r7VoAAACuWIkuSzVo0EBTpkzRjh071KJFiwKPf48dO7ZUigMAALhcJQo38+fPl6+vrzZv3qzNmzc7zLPZbIQbAADgNCUKN4cOHSrtOgAAAEpFie65AQAAcFUl/hC/I0eO6JNPPlFSUpKysrIc5s2ePfuKCwMAACiJEoWb9evXq1+/fqpbt6727dun5s2b6/DhwzLGqG3btqVdIwAAQLGV6LJUZGSkJk6cqB9//FHe3t766KOPlJycrK5du/L5NwAAwKlKFG727t2r4cOHS5Lc3d119uxZ+fr6asaMGXr55ZdLtUAAAIDLUaJwU65cOWVmZkqSatasqV9++cU+78SJE6VTGQAAQAmUKNx06NBBX331lSSpd+/emjhxol544QU99NBD6tChw2WNFRMTo7p168rb21shISHasmVLsZb76quv5O7urtatW19u+QAAwMJKFG5mz56t9u3bS5KmTZumHj16KDY2VkFBQVq4cGGxx4mNjdW4ceM0efJkJSYmqkuXLgoLC1NSUtJFlzt9+rSGDRum22+/vSTlAwAACyvR01L16tWz/1y2bFnFxMSUaOWzZ8/WyJEjFR4eLkmKjo7W2rVrNXfuXEVFRRW53COPPKLBgwfLzc1NH3/8cYnWDQAArKlEZ27q1aun9PT0Au2nTp1yCD4Xk5WVpYSEBIWGhjq0h4aGatu2bUUut3jxYv3yyy+aOnXq5RUNAABuCCU6c3P48GHl5uYWaM/MzNTRo0eLNcaJEyeUm5urgIAAh/aAgAClpqYWuszPP/+sp59+Wlu2bJG7e/FKz8zMtN/8LEkZGRnFWg4AAFyfLivcfPLJJ/af165dKz8/P/t0bm6u1q9fr+Dg4MsqwGazOUwbYwq05Y8/ePBgTZ8+XQ0bNiz2+FFRUZo+ffpl1QQAAK5flxVu7r77bknnAkn+59zk8/DwUHBwsGbNmlWssfz9/eXm5lbgLE1aWlqBszmSdObMGe3cuVOJiYl67LHHJEl5eXkyxsjd3V3r1q1T9+7dCywXGRmpCRMm2KczMjIUGBhYrBoBAMD157LCTV5eniSpbt26+uabb+Tv71/iFXt6eiokJETx8fHq37+/vT0+Pl533XVXgf4VKlTQDz/84NAWExOjDRs26MMPP1TdunULXY+Xl5e8vLxKXCcAALi+lOiem0OHDhVoO3XqlCpWrHhZ40yYMEFDhw5Vu3bt1LFjR82fP19JSUkaPXq0pHNnXY4ePaqlS5eqTJkyat68ucPy1apVk7e3d4F2AABw4yrR01Ivv/yyYmNj7dP333+/KleurFq1aum7774r9jgDBw5UdHS0ZsyYodatW+vLL79UXFycgoKCJEkpKSmX/MwbAACA85Uo3Lz55pv2+1bi4+P1xRdfaM2aNQoLC9OTTz55WWNFRETo8OHDyszMVEJCgm699Vb7vCVLlmjTpk1FLjtt2jTt2rWrJJsAAAAsqkSXpVJSUuzhZvXq1RowYIBCQ0MVHBxs/+RiAAAAZyjRmZtKlSopOTlZkrRmzRrdcccdks49xl3Y598AAABcKyU6c3PPPfdo8ODBuummm5Senq6wsDBJ0q5du9SgQYNSLRAAAOBylCjcvPbaawoODlZycrJmzpwpX19fSecuV0VERJRqgQAAAJejROHGw8NDkyZNKtA+bty4K60HAADgihQ73HzyyScKCwuTh4eHw9cwFKZfv35XXBgAAEBJFDvc3H333UpNTVW1atXsX8NQGJvNxk3FAADAaYodbvK/euHCnwEAAFzJZd9zk5eXpyVLlmjlypU6fPiwbDab6tWrp3vvvVdDhw4t9Bu9AQAArpXL+pwbY4z69eun8PBwHT16VC1atFCzZs10+PBhjRgxwuELMAEAAJzhss7cLFmyRF9++aXWr1+v2267zWHehg0bdPfdd2vp0qUaNmxYqRYJAABQXJd15mb58uV65plnCgQbSerevbuefvppLVu2rNSKAwAAuFyXFW6+//573XnnnUXODwsLu6xvBQcAAChtlxVuTp48qYCAgCLnBwQE6Pfff7/iogAAAErqssJNbm6u3N2Lvk3Hzc1NOTk5V1wUAABASV3WDcXGGI0YMUJeXl6Fzs/MzCyVogAAAErqssLN8OHDL9mHJ6UAAIAzXVa4Wbx48dWqAwAAoFRc1j03AAAAro5wAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALMXp4SYmJkZ169aVt7e3QkJCtGXLliL7bt26VZ07d1aVKlXk4+Ojxo0b67XXXruG1QIAAFfn7syVx8bGaty4cYqJiVHnzp315ptvKiwsTHv27FGdOnUK9C9Xrpwee+wxtWzZUuXKldPWrVv1yCOPqFy5cho1apQTtgAAALgap565mT17tkaOHKnw8HA1adJE0dHRCgwM1Ny5cwvt36ZNGw0aNEjNmjVTcHCwhgwZop49e170bA8AALixOO3MTVZWlhISEvT00087tIeGhmrbtm3FGiMxMVHbtm3T888/fzVKtBZjpOy/nF3FtZWVe97Pf0lyc1opTuFRVrLZnF0FAFxzTgs3J06cUG5urgICAhzaAwIClJqaetFla9eurePHjysnJ0fTpk1TeHh4kX0zMzOVmZlpn87IyLiywq9HxkiLekrJXzu7kmvLeElafO7nVxpItsyLdrecwA7SQ2sIOABuOE6950aSbBf8w2uMKdB2oS1btuiPP/7Qjh079PTTT6tBgwYaNGhQoX2joqI0ffr0Uqv3upT9140XbCSVtWXqsPdgZ5fhPMk7zh17z3LOrgQArimnhRt/f3+5ubkVOEuTlpZW4GzOherWrStJatGihY4dO6Zp06YVGW4iIyM1YcIE+3RGRoYCAwOvsPrr2KQDkmdZZ1eBqynrL+nVBs6uAgCcxmnhxtPTUyEhIYqPj1f//v3t7fHx8brrrruKPY4xxuGy04W8vLzk5eV1RbVaimdZ/icPALA0p16WmjBhgoYOHap27dqpY8eOmj9/vpKSkjR69GhJ5866HD16VEuXLpUkvfHGG6pTp44aN24s6dzn3rz66qt6/PHHnbYNAADAtTg13AwcOFDp6emaMWOGUlJS1Lx5c8XFxSkoKEiSlJKSoqSkJHv/vLw8RUZG6tChQ3J3d1f9+vX10ksv6ZFHHnHWJgAAABfj9BuKIyIiFBERUei8JUuWOEw//vjjnKUBAAAX5fSvXwAAAChNhBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGApTg83MTExqlu3rry9vRUSEqItW7YU2XflypXq0aOHqlatqgoVKqhjx45au3btNawWAAC4OqeGm9jYWI0bN06TJ09WYmKiunTporCwMCUlJRXa/8svv1SPHj0UFxenhIQE3Xbbberbt68SExOvceUAAMBVOTXczJ49WyNHjlR4eLiaNGmi6OhoBQYGau7cuYX2j46O1lNPPaV//OMfuummm/Tiiy/qpptu0qeffnqNKwcAAK7KaeEmKytLCQkJCg0NdWgPDQ3Vtm3bijVGXl6ezpw5o8qVK1+NEgEAwHXI3VkrPnHihHJzcxUQEODQHhAQoNTU1GKNMWvWLP35558aMGBAkX0yMzOVmZlpn87IyChZwQAA4Lrg9BuKbTabw7QxpkBbYZYvX65p06YpNjZW1apVK7JfVFSU/Pz87K/AwMArrhkAALgup4Ubf39/ubm5FThLk5aWVuBszoViY2M1cuRIffDBB7rjjjsu2jcyMlKnT5+2v5KTk6+4dgAA4LqcFm48PT0VEhKi+Ph4h/b4+Hh16tSpyOWWL1+uESNG6L333lPv3r0vuR4vLy9VqFDB4QUAAKzLaffcSNKECRM0dOhQtWvXTh07dtT8+fOVlJSk0aNHSzp31uXo0aNaunSppHPBZtiwYZozZ446dOhgP+vj4+MjPz8/p20HAABwHU4NNwMHDlR6erpmzJihlJQUNW/eXHFxcQoKCpIkpaSkOHzmzZtvvqmcnByNGTNGY8aMsbcPHz5cS5YsudblAwAAF+TUcCNJERERioiIKHTehYFl06ZNV78gAABwXXP601IAAACliXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAsxenhJiYmRnXr1pW3t7dCQkK0ZcuWIvumpKRo8ODBatSokcqUKaNx48Zdu0IBAMB1wanhJjY2VuPGjdPkyZOVmJioLl26KCwsTElJSYX2z8zMVNWqVTV58mS1atXqGlcLAACuB04NN7Nnz9bIkSMVHh6uJk2aKDo6WoGBgZo7d26h/YODgzVnzhwNGzZMfn5+17haAABwPXBauMnKylJCQoJCQ0Md2kNDQ7Vt2zYnVQUAAK537s5a8YkTJ5Sbm6uAgACH9oCAAKWmppbaejIzM5WZmWmfzsjIKLWxAQCA63H6DcU2m81h2hhToO1KREVFyc/Pz/4KDAwstbEBAIDrcVq48ff3l5ubW4GzNGlpaQXO5lyJyMhInT592v5KTk4utbEBAIDrcVq48fT0VEhIiOLj4x3a4+Pj1alTp1Jbj5eXlypUqODwAgAA1uW0e24kacKECRo6dKjatWunjh07av78+UpKStLo0aMlnTvrcvToUS1dutS+zK5duyRJf/zxh44fP65du3bJ09NTTZs2dcYmAAAAF+PUcDNw4EClp6drxowZSklJUfPmzRUXF6egoCBJ5z6078LPvGnTpo3954SEBL333nsKCgrS4cOHr2XpAADARTk13EhSRESEIiIiCp23ZMmSAm3GmKtcEQAAuJ45/WkpAACA0kS4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAluL0cBMTE6O6devK29tbISEh2rJly0X7b968WSEhIfL29la9evU0b968a1QpAAC4Hjg13MTGxmrcuHGaPHmyEhMT1aVLF4WFhSkpKanQ/ocOHVKvXr3UpUsXJSYm6plnntHYsWP10UcfXePKAQCAq3JquJk9e7ZGjhyp8PBwNWnSRNHR0QoMDNTcuXML7T9v3jzVqVNH0dHRatKkicLDw/XQQw/p1VdfvcaVAwAAV+W0cJOVlaWEhASFhoY6tIeGhmrbtm2FLrN9+/YC/Xv27KmdO3cqOzv7qtUKAACuH+7OWvGJEyeUm5urgIAAh/aAgAClpqYWukxqamqh/XNycnTixAnVqFGjwDKZmZnKzMy0T58+fVqSlJGRcaWbcP3I+lPKNOd+zsiQPHOdWw+uLo73DeWv7L+Ue/bcMc7IyFCOR46TK8LVdCMf7/y/28aYS/Z1WrjJZ7PZHKaNMQXaLtW/sPZ8UVFRmj59eoH2wMDAyy3VGl6q6ewKcC1xvG8oNR4t+B88WNeNerzPnDkjPz+/i/ZxWrjx9/eXm5tbgbM0aWlpBc7O5KtevXqh/d3d3VWlSpVCl4mMjNSECRPs03l5eTp58qSqVKly0RAFAABchzFGZ86cUc2al/5Pm9PCjaenp0JCQhQfH6/+/fvb2+Pj43XXXXcVukzHjh316aefOrStW7dO7dq1k4eHR6HLeHl5ycvLy6GtYsWKV1Y8AAC45i51xiafU5+WmjBhghYsWKBFixZp7969Gj9+vJKSkjR69GhJ5866DBs2zN5/9OjR+vXXXzVhwgTt3btXixYt0sKFCzVp0iRnbQIAAHAxTr3nZuDAgUpPT9eMGTOUkpKi5s2bKy4uTkFBQZKklJQUh8+8qVu3ruLi4jR+/Hi98cYbqlmzpv7973/r3nvvddYmAAAAF2MzxbntGAAA4Drh9K9fAAAAKE2EGwAAYCmEGwAAYCmEGwAAYCmEGxe1Y8cO3X///apRo4Y8PT1VvXp13Xfffdq+fXuBvtOmTZPNZtOJEyeuWj1bt25VeHi4QkJC5OXlJZvNpsOHD1+19d1oXOl45+bmavbs2brzzjtVu3ZtlS1bVk2aNNHTTz+tU6dOXZV13mhc6XhL0r///W916NBB/v7+8vLyUp06dfTPf/5Tu3fvvmrrvJG42vE+nzFGt956q2w2mx577LFrss5rgXDjgl5//XV17txZR44c0cyZM/XFF1/o1Vdf1dGjR3XLLbfoP//5zzWvaf369friiy9Up04dderU6Zqv38pc7XifPXtW06ZNU1BQkKKjoxUXF6eHH35Y8+fPV+fOnXX27NlrWo/VuNrxlqT09HSFhYVpwYIFWrdunaZPn67ExES1b99e+/btu+b1WIkrHu/zvfHGGzpw4IBTa7gqDFzK1q1bTZkyZUyfPn1Mdna2w7zs7GzTp08fU6ZMGbN161Z7+9SpU40kc/z48atWV25urv3nV155xUgyhw4dumrru1G44vHOyckxJ06cKNC+YsUKI8m88847V2W9NwJXPN5F2bNnj5FkpkyZck3XayWufrwPHTpkfH19zcqVK40kM2bMmKu+zmuFMzcuJioqSjabTXPnzpW7u+NnLLq7uysmJkY2m00vvfRSgWWTk5N1zz33qEKFCvLz89OQIUN0/Phxhz4bNmxQt27dVKVKFfn4+KhOnTq699579ddff120rjJleKtcDa54vN3c3Ar9rrabb77Zvl6UjCse76JUrVrVXhdKxtWP96hRo9SjRw+Hr0CyCv5iuZDc3Fxt3LhR7dq1U+3atQvtExgYqJCQEG3YsEG5ubkO8/r3768GDRroww8/1LRp0/Txxx+rZ8+eys7OliQdPnxYvXv3lqenpxYtWqQ1a9bopZdeUrly5ZSVlXXVtw+OrrfjvWHDBklSs2bNLntZXB/HOzc3V5mZmfrpp58UHh6uatWq6cEHH7yyDb9BufrxXrBggf73f//X6ZfFrhpnnzrC/0lNTTWSzD//+c+L9hs4cKCRZI4dO2aM+b/TmOPHj3fot2zZMiPJvPvuu8YYYz788EMjyezateuK6uSyVOm4Xo63McYcOXLEBAQEmHbt2jlcokTxXQ/H28vLy0gykkzDhg3Nnj17SjzWjc6Vj/eRI0eMn5+fefPNN+1t4rIUnM38/2/MsNlsDu0PPPCAw/SAAQPk7u6ujRs3SpJat24tT09PjRo1Sm+//bYOHjx4bQrGFXH28T558qR69eolY4xiY2O5RHmVOfN4b9u2Tdu3b9e7776r8uXL67bbbuOJqavMGcd79OjRatWqlR5++OErrN518a+UC/H391fZsmV16NChi/Y7fPiwypYtq8qVKzu0V69e3WHa3d1dVapUUXp6uiSpfv36+uKLL1StWjWNGTNG9evXV/369TVnzpzS3RAUy/VwvH///Xf16NFDR48eVXx8vOrVq1fsZeHoejjebdu2VYcOHfTAAw9o48aNMsbomWeeKfby+D+uerw//PBDrVmzRjNnztTp06d16tQp+0c8ZGVl6dSpU/ZLX9czwo0LcXNz02233aadO3fqyJEjhfY5cuSIEhIS1L17d7m5uTnMS01NdZjOyclRenq6w82hXbp00aeffqrTp09rx44d6tixo8aNG6f333+/9DcIF+Xqx/v333/XHXfcoUOHDik+Pl4tW7YswVYin6sf7wuVL19ejRs31v79+y97Wbju8f7xxx+Vk5OjDh06qFKlSvaXJL311luqVKmSPvvss5Jutssg3LiYyMhIGWMUERFR4Aaz3NxcPfroozLGKDIyssCyy5Ytc5j+4IMPlJOTo27duhXo6+bmpvbt2+uNN96QJH377beltxEoNlc93vnB5uDBg1q3bp3atGlzmVuGwrjq8S7MiRMn9MMPP6hBgwaXvSzOccXjPWLECG3cuLHAS5Luvvtubdy4UbfccsvlbqrL4Rk/F9O5c2dFR0dr3LhxuuWWW/TYY4+pTp06SkpK0htvvKGvv/5a0dHRhX6Q3sqVK+Xu7q4ePXpo9+7dmjJlilq1aqUBAwZIkubNm6cNGzaod+/eqlOnjv7++28tWrRIknTHHXdctK7jx49r8+bNkqQffvhBkvT555+ratWqqlq1qrp27Vqau+GG4YrH++zZs+rZs6cSExMVHR2tnJwc7dixwz6/atWqql+/finviRuDKx7v06dPq0ePHho8eLBuuukm+fj4aP/+/ZozZ44yMzM1derUq7MzbgCueLyDg4MVHBxc6LxatWoVGp6uS864ixmXtn37dnPfffeZgIAA4+7ubqpVq2buueces23btgJ98++uT0hIMH379jW+vr6mfPnyZtCgQfY78PPH7N+/vwkKCjJeXl6mSpUqpmvXruaTTz65ZD0bN260P0Vx4atr166luek3JFc63ocOHSryWEsyw4cPL+3Nv+G40vH++++/TXh4uGnSpInx9fU17u7upnbt2mbIkCFm9+7dpb7tNyJXOt5FkcWelrIZ8/9v1QYAALAA7rkBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBUCqCg4MVHR3t7DJKzaZNm2Sz2exfKgjg+kG4AXBJycnJGjlypGrWrClPT08FBQXpiSeesH9D8fWuW7duGjdunENbp06dlJKSIj8/P+cUBaDECDcALurgwYNq166d9u/fr+XLl+vAgQOaN2+e1q9fr44dO+rkyZNOqSs3N1d5eXlXbXxPT09Vr15dNpvtqq0DwNVBuAFwUWPGjJGnp6fWrVunrl27qk6dOgoLC9MXX3yho0ePavLkyfa+Z86c0eDBg+Xr66uaNWvq9ddfdxhr2rRpqlOnjry8vFSzZk2NHTvWPi8rK0tPPfWUatWqpXLlyql9+/batGmTff6SJUtUsWJFrV69Wk2bNpWXl5feeusteXt7F7h0NHbsWPuXuaanp2vQoEGqXbu2ypYtqxYtWmj58uX2viNGjNDmzZs1Z84c2Ww22Ww2HT58uNDLUh999JGaNWsmLy8vBQcHa9asWQ7rDQ4O1osvvqiHHnpI5cuXV506dTR//nyHbXzsscdUo0YNeXt7Kzg4WFFRUZd9TABcgrO/3AqA60pPTzc2m828+OKLhc5/+OGHTaVKlUxeXp4JCgoy5cuXN1FRUWbfvn3m3//+t3FzczPr1q0zxhizYsUKU6FCBRMXF2d+/fVX8/XXX5v58+fbxxo8eLDp1KmT+fLLL82BAwfMK6+8Yry8vMz+/fuNMcYsXrzYeHh4mE6dOpmvvvrK/PTTT+aPP/4wAQEBZsGCBfZxcnJyTEBAgHnzzTeNMcYcOXLEvPLKKyYxMdH88ssv9rp27NhhjDHm1KlTpmPHjubhhx82KSkpJiUlxeTk5Ni/LPb33383xhizc+dOU6ZMGTNjxgyzb98+s3jxYuPj42MWL15sX3dQUJCpXLmyeeONN8zPP/9soqKiTJkyZczevXuNMca88sorJjAw0Hz55Zfm8OHDZsuWLea9994rnYMFwI5wA6BIO3bsMJLMqlWrCp0/e/ZsI8kcO3bMBAUFmTvvvNNh/sCBA01YWJgxxphZs2aZhg0bmqysrALjHDhwwNhsNnP06FGH9ttvv91ERkYaY86FG0lm165dDn3Gjh1runfvbp9eu3at8fT0NCdPnixyu3r16mUmTpxon+7atat54oknHPpcGG4GDx5sevTo4dDnySefNE2bNrVPBwUFmSFDhtin8/LyTLVq1czcuXONMcY8/vjjpnv37iYvL6/I2gBcOS5LASgxY4wk2e9L6dixo8P8jh07au/evZKk+++/X2fPnlW9evX08MMPa9WqVcrJyZEkffvttzLGqGHDhvL19bW/Nm/erF9++cU+nqenp1q2bOmwjgceeECbNm3Sb7/9JklatmyZevXqpUqVKkk6d2/OCy+8oJYtW6pKlSry9fXVunXrlJSUdFnbunfvXnXu3NmhrXPnzvr555+Vm5trbzu/PpvNpurVqystLU3SuUtgu3btUqNGjTR27FitW7fusmoAUDyEGwBFatCggWw2m/bs2VPo/J9++kmVKlWSv79/kWPkB5/AwEDt27dPb7zxhnx8fBQREaFbb71V2dnZysvLk5ubmxISErRr1y77a+/evZozZ459LB8fnwI3+N58882qX7++3n//fZ09e1arVq3SkCFD7PNnzZql1157TU899ZQ2bNigXbt2qWfPnsrKyrqsfWGMKbDu/HB3Pg8PjwLbn3/jc9u2bXXo0CE999xzOnv2rAYMGKD77rvvsuoAcGnuzi4AgOuqUqWKevTooZiYGI0fP14+Pj72eampqVq2bJmGDRtm/6O/Y8cOh+V37Nihxo0b26d9fHzUr18/9evXT2PGjFHjxo31ww8/qE2bNsrNzVVaWpq6dOly2XUOHjxYy5YtU+3atVWmTBn17t3bPm/Lli2666677IEnLy9PP//8s5o0aWLv4+np6XD2pTBNmzbV1q1bHdq2bdumhg0bys3Nrdi1VqhQQQMHDtTAgQN133336c4779TJkydVuXLlYo8B4OI4cwPgov7zn/8oMzNTPXv21Jdffqnk5GStWbNGPXr0UK1atfTCCy/Y+3711VeaOXOm9u/frzfeeEMrVqzQE088Ienc004LFy7Ujz/+qIMHD+qdd96Rj4+PgoKC1LBhQz3wwAMaNmyYVq5cqUOHDumbb77Ryy+/rLi4uEvW+MADD+jbb7/VCy+8oPvuu0/e3t72eQ0aNFB8fLy2bdumvXv36pFHHlFqaqrD8sHBwfr66691+PBhnThxotBHzCdOnKj169frueee0/79+/X222/rP//5jyZNmlTsffnaa6/p/fff108//aT9+/drxYoVql69uipWrFjsMQBcGuEGwEXddNNN2rlzp+rXr6+BAweqfv36GjVqlG677TZt377d4YzDxIkTlZCQoDZt2ui5557TrFmz1LNnT0lSxYoV9dZbb6lz585q2bKl1q9fr08//VRVqlSRJC1evFjDhg3TxIkT1ahRI/Xr109ff/21AgMDi1XjP/7xD33//fd64IEHHOZNmTJFbdu2Vc+ePdWtWzdVr15dd999t0OfSZMmyc3NTU2bNlXVqlULvR+nbdu2+uCDD/T++++refPmevbZZzVjxgyNGDGi2PvS19dXL7/8stq1a6d//OMfOnz4sOLi4lSmDP8UA6XJZgq7aAwAAHCd4r8LAADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUv4fh+trbJ3QbWoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "dissimilarity_matrix = np.array([[0, 0.3, 0.4, 0.7],\n",
    "                                 [0.3, 0, 0.5, 0.8],\n",
    "                                 [0.4, 0.5, 0, 0.45],\n",
    "                                 [0.7, 0.8, 0.45, 0]])\n",
    "\n",
    "# Perform hierarchical clustering with complete linkage\n",
    "linkage_matrix = linkage(squareform(dissimilarity_matrix), method='complete')\n",
    "\n",
    "# Plot the dendrogram\n",
    "dendrogram(linkage_matrix, labels=['Obs 1', 'Obs 2', 'Obs 3', 'Obs 4'])\n",
    "\n",
    "# Add labels and show the plot\n",
    "plt.title('Dendrogram for Complete Linkage')\n",
    "plt.xlabel('Observations')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4122f0",
   "metadata": {},
   "source": [
    "**(b). Repeat (a), this time using single linkage clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c7bb1c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform hierarchical clustering with single linkage\n",
    "linkage_matrix_single = linkage(squareform(dissimilarity_matrix), method='single')\n",
    "\n",
    "# Plot the dendrogram\n",
    "dendrogram(linkage_matrix_single, labels=['Obs 1', 'Obs 2', 'Obs 3', 'Obs 4'])\n",
    "\n",
    "# Add labels and show the plot\n",
    "plt.title('Dendrogram for Single Linkage')\n",
    "plt.xlabel('Observations')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f4911b",
   "metadata": {},
   "source": [
    "**(c). Suppose that we cut the dendogram obtained in (a) such that two clusters result. Which observations are in each cluster?**\n",
    "\n",
    "The observations in the cluster are:\n",
    "\n",
    "> - {1, 2}\n",
    "> - {3, 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0290ee7",
   "metadata": {},
   "source": [
    "**(d). Suppose that we cut the dendogram obtained in (b) such that two clusters result. Which observations are in each cluster?**\n",
    "\n",
    "The observations in the cluster are:\n",
    "\n",
    "> - {1, 2, 3}\n",
    "> - {4}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8030f1",
   "metadata": {},
   "source": [
    "**(e). It is mentioned in the chapter that at each fusion in the dendrogram, the position of the two clusters being fused can be swapped without changing the meaning of the dendrogram. Draw a dendrogram that is equivalent to the dendrogram in (a), for which two or more of the leaves are repositioned, but for which the meaning of the dendrogram is the same**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dea8f18",
   "metadata": {},
   "source": [
    "![](images/IMG12-6-2-e.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e9596e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
